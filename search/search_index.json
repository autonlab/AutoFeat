{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":""},{"location":"#autonfeat","title":"\u23f3 AutonFeat \u231b","text":"<p>A high performance library for time series featurization. </p> <p></p>"},{"location":"#what","title":"What? \ud83d\ude4b","text":"<p><code>AutonFeat</code> is a high-performant domain agnostic package for time series featurization. Despite the domain agnostic focus of the package, we recognize the benefit of domain knowledge and have included a few domain specific featurizers for popular domains like healthcare. With time series data, as with any data, it is often helpful to perform preprocessing before extracting information from it such as exploring the frequency domain as well as the time domain. We have provided a number of preprocessors that can transform the distribution or space to a form more amenable to certain featurizations. The package is lightweight, fast and easy to use. We hope you enjoy it! \ud83c\udf89</p> <p>Here's an illustration of what featurization looks like:</p> <p></p>"},{"location":"#why","title":"Why? \ud83e\udd14","text":"<p>To prevent others from reinventing the wheel, we have compiled a featurization library for dealing with time-series data. We have also included a number of preprocessors to transform the data into a form more amenable to certain featurizations. Finally, our goal was to make this package without too many dependencies and overhead. Here are some of our design objectives:</p> <ul> <li>Simple: The package must be easy to use and require as little user input as possible.</li> <li>Interpretable: The software abstractions must be intuitive, easy to understand and easy to debug.</li> <li>Fast: The tool must be fast enough to be used in large scale production environments.</li> <li>Flexible: The package must be modular and allow for easy extensibility to leverage community contributions.</li> </ul>"},{"location":"#assumptions","title":"Assumptions \ud83e\uddd0","text":"<p>Note: We have made a few assumptions to start out with but we are working on making the package more flexible and robust. If you have any suggestions, please open an issue or PR! \ud83d\ude42</p> <ul> <li>The input data is a 1D time series in the form of a numpy array.</li> <li>If there are missing values, they must be represented by <code>np.nan</code> to be detected, otherwise, gaps in the time series are not detected.</li> </ul>"},{"location":"#installation","title":"Installation \ud83d\udce6","text":"<pre><code>pip install autonfeat\n</code></pre> <p>Check out our quickstart guide for more.</p> <p>Installing inside a python virtual environment or a conda environment is recommended.</p>"},{"location":"#features","title":"Features \ud83e\udde0","text":"<p>We provide a variety of features ranging from domain agnostic to domain specific (e.g. healthcare) featurizers, as well as a number of preprocessors to transform the data into a form more amenable to certain featurizations. This list is constantly growing so please check back often! Feel free to contribute your own featurizers and open a PR! \ud83c\udf89</p>"},{"location":"#contributing","title":"Contributing \ud83e\udd1d","text":"<p>We'd love to hear from you! If you've found anything missing, feel free to open an issue or PR! \ud83d\ude42</p> <p>Learn more about contributing here.</p>"},{"location":"#authors","title":"Authors \ud83d\udc68\u200d\ud83d\udcbb","text":"<p>Dhruv Srikanth</p> <p>Auton Lab</p>"},{"location":"#license","title":"License \ud83d\udcdd","text":"<p>For more details, check out the license here.</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/api/","title":"Reference Guide","text":""},{"location":"api/api/#api_reference_guide","title":"API Reference Guide","text":"<p>The <code>AutonFeat</code> package is made up of several submodules. The following table provides a brief description of each submodule.</p> Submodule Description <code>autonfeat.core</code> Contains the core functionality of the package. <code>autonfeat.common</code> Contains common featurizers. <code>autonfeat.functional</code> Contains the functional form of featurizers. <code>autonfeat.health</code> Contains healthcare related featurizers. <code>autonfeat.preprocess</code> Contains preprocessors. <code>autonfeat.preprocess.functional</code> Contains the functional form of preprocessors. <code>autonfeat.utils</code> Contains utility functions. <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/features/","title":"Feature Extractors","text":""},{"location":"api/features/#features","title":"Features","text":"<p>Feature extractors are used, as the name suggests, to extract features from a signal. <code>AutonFeat</code> provides a wide range of feature extractors that can be used to extract features from a signal. The following sections describe the various feature extractors that are available in <code>AutonFeat</code>.</p>"},{"location":"api/features/#domain_agnostic","title":"Domain Agnostic","text":"<p>Domain agnostic features are applicable to most signals irrespective of the domain.</p>"},{"location":"api/features/#summary_statistics","title":"Summary Statistics","text":"Feature Description Endpoint Max Maximum value of the signal <code>MaxTransform</code> Min Minimum value of the signal <code>MinTransform</code> Mean Mean of the signal <code>MeanTransform</code> Median Median of the signal <code>MedianTransform</code> Standard Deviation Standard deviation of the signal <code>StdTransform</code> Variance Variance of the signal <code>VarTransform</code> Quantile Quantile of the signal <code>QuantileTransform</code> Range Range of the signal <code>RangeTransform</code> IQR Interquartile range of the signal <code>IQRTransform</code> N Valid Number of valid values in the signal <code>NValidTransform</code> Skewness Skewness of the signal <code>SkewnessTransform</code> Kurtosis Kurtosis of the signal <code>KurtosisTransform</code>"},{"location":"api/features/#data_sparsity_measures","title":"Data Sparsity Measures","text":"Feature Description Endpoint Data Density Ratio of valid values to window size <code>DataDensityTransform</code> Data Sparsity Ratio of missing values to window size <code>DataSparsityTransform</code>"},{"location":"api/features/#information_theoretic_measures","title":"Information Theoretic Measures","text":"Feature Description Endpoint Shannon Entropy Shannon entropy of the signal <code>EntropyTransform</code> KL Divergence KL divergence of the signal with another distribution <code>EntropyTransform</code> Sample Entropy Sample entropy of the signal <code>SampleEntropyTransform</code> Approximate Entropy Approximate entropy of the signal <code>ApproxEntropyTransform</code> Cross Entropy Cross entropy of the signal with another distribution <code>CrossEntropyTransform</code>"},{"location":"api/features/#domain_specific","title":"Domain Specific","text":"<p>Domain expertise almost always helps in extracting better features. <code>AutonFeat</code> provides a wide range of domain specific features that can be used to extract features from a signal. The following sections describe the various domain specific feature extractors that are available in <code>AutonFeat</code>.</p>"},{"location":"api/features/#biomedical_and_physiological_signals","title":"Biomedical, and Physiological Signals","text":"<p>(Coming Soon)</p> Feature Description Endpoint"},{"location":"api/features/#functional_form","title":"Functional Form","text":"<p>A functional form for each of the transforms above is also provided for convenience. Check out the <code>autonfeat.functional</code> sub-module for more details.</p>"},{"location":"api/features/#custom_featurizers","title":"Custom Featurizers","text":"<p>It is possible to design custom features while extending the functionality of <code>AutonFeat</code>. The <code>Transform</code> class is an abstraction representing a featurizer. When defining a custom featurizer, one can utilize the efficiency of the <code>SlidingWindow</code> abstraction by inhering defining the featurizer to inherit from <code>Transform</code>. The following example demonstrates how to create a custom feature that computes the mean of the signal.</p> <pre><code>import numpy as np\nfrom typing import Callable, Union\nfrom autonfeat.core import Transform\nclass MeanTransform(Transform):\ndef __init__(self, name: str = \"Mean\") -&gt; None:\nsuper().__init__(name=name)\ndef __call__(self, signal_window: np.ndarray, where: Callable[[Union[int, float, np.int_, np.float_]], Union[bool, np.bool_]] = lambda x: not np.isnan(x)) -&gt; Union[np.float_, np.int_]:\nwhere_fn = np.vectorize(pyfunc=where)\nreturn np.mean(x, where=where_fn(x))\n</code></pre> <p>This can then be passed as the featurizer to be applied at every sliding window interval as such - </p> <pre><code>import autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = MeanTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>See this for more examples on how to use feature extractors in <code>AutonFeat</code>.</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/approx_entropy_transform/","title":"Approximate Entropy Transform","text":""},{"location":"api/common/approx_entropy_transform/#approximate_entropy_transform","title":"Approximate Entropy Transform","text":"<p>The approximate entropy transform computes the approximate entropy of a window. When combined with the <code>SlidingWindow</code> abstraction, the approximate entropy transform can be used to compute the <code>approximate entropy</code> feature of a time series. It is used to quantify the amount of regularity and the unpredictability signals. Approximate entropy measures the likelihood that similar patterns of observations will not be followed by these similar patterns, therefore a time-series signal that exhibits seasonality or other kinds of repetitive patterns will have a relatively small approximate entropy whereas signals without such a repetitive nature will exhibit a high value of approximate entropy [1]. It is defined as:</p> \\[ ApEn(m, r) = \\phi_{m}(r) - \\phi_{m+1}(r) \\] \\[ \\phi_{m}(r) = \\frac{1}{N-m+1} \\sum_{i=1}^{N-m+1} \\ln C_m^i(r) \\] \\[ C_m^i(r) = \\frac{1}{N-m+1} \\sum_{j=1}^{N-m+1} \\Theta(r - ||x_{i+j-1} - x_{j}||) \\] <p>where \\(m\\) is the embedding dimension, \\(r\\) is the tolerance, \\(N\\) is the length of the signal, \\(x_i\\) is the \\(i^{th}\\) sample of the signal, and \\(\\Theta\\) is the Heaviside step function.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the approximate entropy of the signal.</p> References <p>Approximate Entropy - https://en.wikipedia.org/wiki/Approximate_entropy</p>"},{"location":"api/common/approx_entropy_transform/#autonfeat.common.ApproxEntropyTransform.__call__","title":"<code>__call__(signal_window, m, r, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the approximate entropy of the values in <code>x</code> where <code>where</code> is <code>True</code>. It used to quantify the amount of regularity and the unpredictability of fluctuations in the signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal to find the approximate entropy of.</p> required <code>m</code> <code>Union[int, int_]</code> <p>The length of the template vector.</p> required <code>r</code> <code>Union[int, int_]</code> <p>The tolerance.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The approximate entropy of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/common/approx_entropy_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.ApproxEntropyTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x, m=2, r=0.2)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre>"},{"location":"api/common/approx_entropy_transform/#references","title":"References","text":"<p>[1] https://en.wikipedia.org/wiki/Approximate_entropy</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/cross_entropy_transform/","title":"Cross Entropy Transform","text":""},{"location":"api/common/cross_entropy_transform/#cross_entropy_transform","title":"Cross Entropy Transform","text":"<p>The cross-entropy transform computes the cross entropy between two discrete probability distributions. The cross entropy is defined as:</p> \\[ H(p, q) = -\\sum_{x} p(x) \\log q(x) \\] <p>where \\(p\\) and \\(q\\) are the two probability distributions. The cross entropy is a measure of the difference between two probability distributions. The cross entropy is zero if and only if the two distributions are identical. The cross entropy is always non-negative i.e. \\(H(p, q) \\geq 0\\).</p> <p>             Bases: <code>Transform</code></p> <p>Compute the cross entropy of the values in <code>pk</code> with respect to <code>qk</code>.</p>"},{"location":"api/common/cross_entropy_transform/#autonfeat.common.CrossEntropyTransform.__call__","title":"<code>__call__(pk, qk, base=None, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the cross entropy of the values in <code>pk</code> with respect to <code>qk</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pk</code> <code>ndarray</code> <p>A discrete probability distribution.</p> required <code>qk</code> <code>ndarray</code> <p>A second discrete probability distribution.</p> required <code>base</code> <code>Optional[Union[int, int_]]</code> <p>The base of the logarithm used to compute the entropy. Default is <code>None</code> which means that the natural logarithm is used.</p> <code>None</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The cross-entropy of the values in <code>pk</code> with respect to <code>qk</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/common/cross_entropy_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx1 = np.random.rand(n_samples)\nx2 = np.random.rand(n_samples)\n# Sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.CrossEntropyTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x1, x2)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/data_density_transform/","title":"Data Density Transform","text":""},{"location":"api/common/data_density_transform/#data_density_transform","title":"Data Density Transform","text":"<p>The data density transform computes the ratio of valid values in a sliding window to the total number of values in the window. See <code>NValidTransform</code> for more details on how valid values are computed. It can be coupled with the <code>SlidingWindow</code> abstraction to compute the <code>data density</code> feature of a time series. It can be defined as:</p> \\[ \\text{density} = \\frac{N_{valid}}{N_{total}} \\] <p>where \\(N_{valid}\\) is the number of valid values in a window \\(W\\) and \\(N_{total}\\) is the total number of values in \\(W\\).</p> <p>             Bases: <code>Transform</code></p> <p>Compute the data density of a signal window <code>x</code>.</p>"},{"location":"api/common/data_density_transform/#autonfeat.common.DataDensityTransform.__call__","title":"<code>__call__(signal_window, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the data density of the array <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to find the data density of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the data density of <code>x</code>.</p>"},{"location":"api/common/data_density_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.DataDensityTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/data_sparsity_transform/","title":"Data Sparsity Transform","text":""},{"location":"api/common/data_sparsity_transform/#data_sparsity_transform","title":"Data Sparsity Transform","text":"<p>The data sparsity transform computes the ratio of invalid values in a sliding window to the total number of values in the window. See <code>NValidTransform</code> for more details on how valid values are computed. Invalid values are computed by computing \\(1 - N_{valid}\\), where \\(N_{valid}\\) is the number of valid values in the signal window. It can be coupled with the <code>SlidingWindow</code> abstraction to compute the <code>data_sparsity</code> feature of a time series. It can be defined as:</p> \\[ \\text{sparsity} = \\frac{N_{invalid}}{N_{total}} \\] <p>where \\(N_{invalid}\\) is the number of invalid values in a window \\(W\\) and \\(N_{total}\\) is the total number of values in \\(W\\).</p> <p>             Bases: <code>Transform</code></p> <p>Compute the data sparsity of a signal window <code>x</code>.</p>"},{"location":"api/common/data_sparsity_transform/#autonfeat.common.DataSparsityTransform.__call__","title":"<code>__call__(signal_window, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the data sparsity of the array <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to find the data sparsity of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the data sparsity of <code>x</code>.</p>"},{"location":"api/common/data_sparsity_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.DataSparsityTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/entropy_transform/","title":"Entropy Transform","text":""},{"location":"api/common/entropy_transform/#entropy_transform","title":"Entropy Transform","text":"<p>The entropy transform computes the entropy of a distribution. The entropy is a measure of the uncertainty of a random variable. The entropy of a distribution is defined as:</p> \\[ H(X) = -\\sum_{i=1}^{n} p(x_i) \\log p(x_i) \\] <p>where \\(p(x_i)\\) is the probability of the \\(i\\)-th outcome. The entropy is maximized when all outcomes are equally likely. The entropy is zero when the distribution is deterministic.</p> <p>We can use the entropy transform to compute the entropy of a single discrete probability distribution using Shannon Entropy. We can also use the entropy transform to compute the relative entropy between two discrete probability distributions. This is also called the Kullback-Leibler (KL) divergence. This is defined as:</p> \\[ D_{KL}(p||q) = H(p, q) = \\sum_{x} p(x) \\log \\frac{p(x)}{q(x)} \\] <p>where \\(p\\) and \\(q\\) are the two probability distributions. The relative entropy is zero if and only if the two distributions are identical. The relative entropy is always non-negative.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the entropy of a distribution, or the KL divergence between two distributions.</p>"},{"location":"api/common/entropy_transform/#autonfeat.common.EntropyTransform.__call__","title":"<code>__call__(pk, qk=None, base=None, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the entropy of the values in <code>pk</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pk</code> <code>ndarray</code> <p>The discrete probability distribution to find the entropy of.</p> required <code>qk</code> <code>Optional[numpy.ndarray]</code> <p>The second discrete probability distribution to find the relative entropy with. Default is <code>None</code>.</p> <code>None</code> <code>base</code> <code>Optional[Union[int, int_]]</code> <p>The base of the logarithm used to compute the entropy. Default is <code>None</code> which means that the natural logarithm is used.</p> <code>None</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The entropy of the values in <code>pk</code> optionally with respect to <code>qk</code> (relative entropy) where <code>where</code> is <code>True</code>.</p>"},{"location":"api/common/entropy_transform/#examples","title":"Examples","text":""},{"location":"api/common/entropy_transform/#shannon_entropy","title":"Shannon Entropy","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.randint(0, 10, n_samples)\n# Sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.EntropyTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre>"},{"location":"api/common/entropy_transform/#kl_divergence","title":"KL Divergence","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx1 = np.random.rand(n_samples)\nx2 = np.random.rand(n_samples)\n# Sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.EntropyTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x1, x2)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/iqr_transform/","title":"IQR Transform","text":""},{"location":"api/common/iqr_transform/#inter-quartile_range_transform","title":"Inter-Quartile Range Transform","text":"<p>The inter-quartile range transform computes the inter-quartile range of the data in a sliding window. The inter-quartile range is the difference between the \\(75^{th}\\) and \\(25^{th}\\) percentiles of the data and can be defined as:</p> \\[ \\text{IQR} = \\text{Q3} - \\text{Q1} \\] <p>where \\(\\text{Q1}\\) and \\(\\text{Q3}\\) are the \\(25^{th}\\) and \\(75^{th}\\) percentiles of the data, respectively.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the inter-quartile range of the values.</p>"},{"location":"api/common/iqr_transform/#autonfeat.common.IQRTransform.__call__","title":"<code>__call__(signal_window, method='linear', where=lambda : not np.isnan(x))</code>","text":"<p>Compute the inter-quartile range of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The array to compute the IQR of.</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantiles. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the IQR of the signal.</p>"},{"location":"api/common/iqr_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.IQRTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/kurtosis_transform/","title":"Kurtosis Transform","text":""},{"location":"api/common/kurtosis_transform/#kurtosis_transform","title":"Kurtosis Transform","text":"<p>The kurtosis transform computes the kurtosis of a window. When combined with the <code>SlidingWindow</code> abstraction, the kurtosis transform can be used to compute the <code>kurtosis</code> feature of a time series. The kurtosis is defined as:</p> \\[ \\kappa = \\begin{cases} \\frac{m_4}{m_2^2} - 3 &amp; \\text{Fisher} \\\\ \\frac{m_4}{m_2^2} &amp; \\text{Pearson} \\end{cases} \\] <p>where \\(m_2\\) and \\(m_4\\) are the second and fourth central moments, respectively. They are defined as:</p> \\[ m_2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2 \\] \\[ m_4 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^4 \\] <p>where \\(N\\) is the number of samples in the window and \\(\\bar{x}\\) is the mean of the window.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the kurtosis of the values in <code>x</code>.</p>"},{"location":"api/common/kurtosis_transform/#autonfeat.common.KurtosisTransform.__call__","title":"<code>__call__(signal_window, fisher=True, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the krutosis of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p> <p>The krutosis is a measure of the \"tailedness\" of a distribution. It is defined as the fourth standardized moment of a distribution, and is calculated as:</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal to compute the krutosis of.</p> required <code>fisher</code> <code>Union[bool, bool_]</code> <p>Whether to use Fisher's definition of kurtosis i.e. subtract 3 from the result. Default is <code>True</code>. If <code>False</code>, the result is the Pearson's definition of kurtosis.</p> <code>True</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>The krutosis of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/common/kurtosis_transform/#examples","title":"Examples","text":""},{"location":"api/common/kurtosis_transform/#fisher_kurtosis","title":"Fisher Kurtosis","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.KurtosisTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre>"},{"location":"api/common/kurtosis_transform/#pearson_kurtosis","title":"Pearson Kurtosis","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.KurtosisTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x, fisher=False)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/max_transform/","title":"Max Transform","text":""},{"location":"api/common/max_transform/#max_transform","title":"Max Transform","text":"<p>The max transform computes the max of a window. When combined with the <code>SlidingWindow</code> abstraction, the max transform can be used to compute the <code>max</code> feature of a time series. The max is defined as:</p> \\[ \\text{max}(x) = \\max_{i=1}^n x_i \\] <p>where \\(x\\) is a vector of length \\(n\\).</p> <p>             Bases: <code>Transform</code></p> <p>Compute the max of the values in <code>x</code>.</p>"},{"location":"api/common/max_transform/#autonfeat.common.MaxTransform.__call__","title":"<code>__call__(signal_window, where=lambda : not np.isnan(x), initial=-np.inf)</code>","text":"<p>Compute the max of the signal window provided.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to find the max of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <code>initial</code> <code>Union[int, float, int_, float_]</code> <p>The initial value to use when computing the max. Default is <code>-np.inf</code>.</p> <code>-inf</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the max of the signal.</p>"},{"location":"api/common/max_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.MaxTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/mean_transform/","title":"Mean Transform","text":""},{"location":"api/common/mean_transform/#mean_transform","title":"Mean Transform","text":"<p>The mean transform computes the mean of a window. When combined with the <code>SlidingWindow</code> abstraction, the mean transform can be used to compute the <code>mean</code> feature of a time series. The mean is defined as:</p> \\[ \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\] <p>where \\(x_i\\) is the \\(i\\)-th element of the window and \\(n\\) is the number of elements in the window.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the mean of the values in <code>x</code>.</p>"},{"location":"api/common/mean_transform/#autonfeat.common.MeanTransform.__call__","title":"<code>__call__(signal_window, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the mean of the signal window provided.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to find the mean of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the mean of the signal.</p>"},{"location":"api/common/mean_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.MeanTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/median_transform/","title":"Median Transform","text":""},{"location":"api/common/median_transform/#median_transform","title":"Median Transform","text":"<p>The median transform computes the median of a window. When combined with the <code>SlidingWindow</code> abstraction, the median transform can be used to compute the <code>median</code> feature of a time series. The median is defined as: (write the formula as two cases for even and odd length vectors and index with i for each case)</p> \\[ \\text{median}(x) = \\begin{cases} 0.5 \\cdot (x_{\\lfloor n/2 \\rfloor} + x_{\\lceil n/2 \\rceil}) &amp; \\text{if $n$ is even} \\\\ x_{\\lfloor n/2 \\rfloor} &amp; \\text{if $n$ is odd} \\end{cases} \\] <p>where \\(x\\) is a vector of length \\(n\\).</p> <p>             Bases: <code>Transform</code></p> <p>Compute the median of the values.</p>"},{"location":"api/common/median_transform/#autonfeat.common.MedianTransform.__call__","title":"<code>__call__(signal_window, method='linear', where=lambda : not np.isnan(x))</code>","text":"<p>Compute the median of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The array to compute the median of.</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantile. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the median of the signal.</p>"},{"location":"api/common/median_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.MedianTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/min_transform/","title":"Min Transform","text":""},{"location":"api/common/min_transform/#max_transform","title":"Max Transform","text":"<p>The min transform computes the min of a window. When combined with the <code>SlidingWindow</code> abstraction, the min transform can be used to compute the <code>min</code> feature of a time series. The min is defined as:</p> \\[ \\text{min}(x) = \\min_{i=1}^n x_i \\] <p>where \\(x\\) is a vector of length \\(n\\).</p> <p>             Bases: <code>Transform</code></p> <p>Compute the min of the values in <code>x</code>.</p>"},{"location":"api/common/min_transform/#autonfeat.common.MinTransform.__call__","title":"<code>__call__(signal_window, where=lambda : not np.isnan(x), initial=np.inf)</code>","text":"<p>Compute the min of the signal window provided.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to find the min of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <code>initial</code> <code>Union[int, float, int_, float_]</code> <p>The initial value to use when computing the min. Default is <code>np.inf</code>.</p> <code>inf</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the min of the signal.</p>"},{"location":"api/common/min_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.MinTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/n_valid_transform/","title":"N-Valid Transform","text":""},{"location":"api/common/n_valid_transform/#n-valid_transform","title":"N-Valid Transform","text":"<p>Compute the number of valid measurements in a sliding window. A valid measurement by default is defined as a measurement that is not <code>np.nan</code>, however this can be altered by passing a validity function to the argument <code>where</code>. The validity function should take a single argument, the measurement, and return <code>True</code> if the measurement is valid, and <code>False</code> otherwise. The transform can be defined as:</p> \\[ \\mathbb{1}_{\\text{valid}}(x_i) = \\begin{cases} 1 &amp; \\text{if } x_i \\text{ is valid} \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\] <p>where \\(x_i\\) is the \\(i\\)-th measurement in the sliding window.</p> \\[ \\text{NValid} = \\sum_{i=1}^n \\mathbb{1}_{\\text{valid}}(x_i) \\] <p>where \\(n\\) is the number of measurements in the sliding window.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the number of valid measurements <code>x</code>.</p>"},{"location":"api/common/n_valid_transform/#autonfeat.common.NValidTransform.__call__","title":"<code>__call__(signal_window, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the number of valid measurements in <code>x</code> where <code>where</code> is <code>True</code> for valid measurements.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to find number of valid measurements in.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the number of valid measurements in <code>x</code>.</p>"},{"location":"api/common/n_valid_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.NValidTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/quantile_transform/","title":"Quantile Transform","text":""},{"location":"api/common/quantile_transform/#quantile_transform","title":"Quantile Transform","text":"<p>The quantile transform computes the q-th quantile of the data in the sliding window. The quantile is computed using the numpy.quantile function. The transform can be combined with the <code>SlidingWindow</code> to compute the quantile of the data in a sliding window. We can use this transform to compute the median of the data in a sliding window by setting <code>q=0.5</code>.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the q-th quantile of the values.</p>"},{"location":"api/common/quantile_transform/#autonfeat.common.QuantileTransform.__call__","title":"<code>__call__(signal_window, q, method='linear', where=lambda : not np.isnan(x))</code>","text":"<p>Compute the q-th quantile of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The array to compute the q-th quantile of.</p> required <code>q</code> <code>Union[float, float_]</code> <p>The quantile to compute. <code>q</code> belongs to [0, 1].</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantile. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p><code>where</code>: A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the q-th quantile of the signal.</p>"},{"location":"api/common/quantile_transform/#examples","title":"Examples","text":""},{"location":"api/common/quantile_transform/#25th_percentile","title":"25th percentile","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.QuantileTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x, q=0.25)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre>"},{"location":"api/common/quantile_transform/#median","title":"Median","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.QuantileTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x, q=0.5)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/range_transform/","title":"Range Transform","text":""},{"location":"api/common/range_transform/#range_transform","title":"Range Transform","text":"<p>The range transform computes the range of the data in the sliding window. When paired with the <code>SlidingWindow</code> abstraction, one can compute the range over a sliding window across a time series. The range is computed as the difference between the maximum and minimum values in the window and can be defined as:</p> \\[ \\text{range} = \\max(x) - \\min(x) \\] <p>where \\(x\\) is the data in the sliding window.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the range of the values.</p>"},{"location":"api/common/range_transform/#autonfeat.common.RangeTransform.__call__","title":"<code>__call__(signal_window, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the range of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The array to compute the range of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the range of the signal.</p>"},{"location":"api/common/range_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.RangeTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/sample_entropy_transform/","title":"Sample Entropy Transform","text":""},{"location":"api/common/sample_entropy_transform/#sample_entropy_transform","title":"Sample Entropy Transform","text":"<p>The sample entropy transform computes the sample entropy of a window. When combined with the <code>SlidingWindow</code> abstraction, the sample entropy transform can be used to compute the <code>sample entropy</code> feature of a time series. Sample entropy is a measure of the complexity of the signal [1]. It is a modification of the approximate entropy (ApEn) algorithm which is implemented here. It is defined as:</p> \\[ \\text{Sample Entropy} = -\\log\\left(\\frac{A}{B}\\right) \\] <p>where \\(A\\) is the number of matches for template vectors of length \\(m\\) and \\(B\\) is the number of matches for template vectors of length \\(m + 1\\). A match is defined as a template vector \\(x_{m_i}\\) that is close to another template vector \\(x_{m_j}\\) in the sense that the maximum absolute difference between their corresponding scalar elements is less than or equal to a threshold \\(r\\).</p> <p>             Bases: <code>Transform</code></p> <p>Compute the sample entropy of the signal.</p> References <p>Sample Entropy -https://en.wikipedia.org/wiki/Sample_entropy</p>"},{"location":"api/common/sample_entropy_transform/#autonfeat.common.SampleEntropyTransform.__call__","title":"<code>__call__(signal_window, m, r, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the sample entropy of the values in <code>x</code> where <code>where</code> is <code>True</code>. It is a measure of the complexity of a signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal to find the sample entropy of.</p> required <code>m</code> <code>Union[int, int_]</code> <p>The length of the template vector.</p> required <code>r</code> <code>Union[int, int_]</code> <p>The tolerance.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The sample entropy of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/common/sample_entropy_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.SampleEntropyTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x, m=2, r=0.2)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre>"},{"location":"api/common/sample_entropy_transform/#references","title":"References","text":"<p>[1] https://en.wikipedia.org/wiki/Sample_entropy</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/skewness_transform/","title":"Skew Transform","text":""},{"location":"api/common/skewness_transform/#skewness_transform","title":"Skewness Transform","text":"<p>The skew transform computes the skewness of a window. When combined with the <code>SlidingWindow</code> abstraction, the skew transform can be used to compute the <code>skew</code> feature of a time series. The skewness is defined as:</p> \\[ \\gamma = \\frac{m_3}{m_2^{3/2}} \\] <p>We use this and correct for statistical bias. The Fisher-Pearson standardized moment coefficient is defined as:</p> \\[ \\Gamma = \\gamma \\sqrt{\\frac{N(N-1)}{N-2}} \\] <p>where \\(m_2\\) and \\(m_3\\) are the second and third central moments, respectively. They are defined as:</p> \\[ m_2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2 \\] \\[ m_3 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^3 \\] <p>where \\(N\\) is the number of samples in the window and \\(\\bar{x}\\) is the mean of the window.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the skewness of the values in <code>x</code>.</p>"},{"location":"api/common/skewness_transform/#autonfeat.common.SkewnessTransform.__call__","title":"<code>__call__(signal_window, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the skewness of the values in <code>x</code> where <code>where</code> is <code>True</code>. The skewness is computed using the Fisher-Pearson standardized coefficient of skewness.</p> <p>The skewness is only computed for valid values i.e. values where <code>where</code> is <code>True</code>. The skewness computed is corrected for statistical bias.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal to compute the skewness of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>The skewness of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/common/skewness_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.SkewnessTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/std_transform/","title":"Std Transform","text":""},{"location":"api/common/std_transform/#standard_deviation_transform","title":"Standard Deviation Transform","text":"<p>The standard deviation transform computes the standard deviation of a window. When combined with the <code>SlidingWindow</code> abstraction, the standard deviation transform can be used to compute the <code>std</code> feature of a time series. The standard deviation is defined as:</p> \\[ \\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2} \\] <p>where \\(x_i\\) is the \\(i\\)-th element of the window, \\(n\\) is the number of elements in the window, and \\(\\mu\\) is the mean of the window.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the standard deviation of the values in <code>x</code>.</p>"},{"location":"api/common/std_transform/#autonfeat.common.StdTransform.__call__","title":"<code>__call__(signal_window, ddof=0, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the standard deviation of the signal window provided.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to find the standard deviation of.</p> required <code>ddof</code> <code>Union[int, int_]</code> <p>The delta degrees of freedom. Default is <code>0</code>. See <code>numpy.std</code> for more information.</p> <code>0</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the standard deviation of the signal.</p>"},{"location":"api/common/std_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.StdTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/common/var_transform/","title":"Var Transform","text":""},{"location":"api/common/var_transform/#variance_transform","title":"Variance Transform","text":"<p>The variance transform computes the variance of a window. When combined with the <code>SlidingWindow</code> abstraction, the variance transform can be used to compute the <code>var</code> feature of a time series. The variance is defined as:</p> \\[ \\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2 \\] <p>where \\(x_i\\) is the \\(i\\)-th element of the window, \\(n\\) is the number of elements in the window, and \\(\\mu\\) is the mean of the window.</p> <p>             Bases: <code>Transform</code></p> <p>Compute the variance of the values in <code>x</code>.</p>"},{"location":"api/common/var_transform/#autonfeat.common.VarTransform.__call__","title":"<code>__call__(signal_window, ddof=0, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the variance of the signal window provided.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to find the variance of.</p> required <code>ddof</code> <code>Union[int, int_]</code> <p>The delta degrees of freedom. Default is <code>0</code>. See <code>numpy.var</code> for more information.</p> <code>0</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the variance of the signal.</p>"},{"location":"api/common/var_transform/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = aft.VarTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/core/fixed_window/","title":"Sliding Window","text":""},{"location":"api/core/fixed_window/#fixed_sliding_window","title":"Fixed Sliding Window","text":"<p>A fixed sliding window is an abstraction that can be used to compute features across a signal using a sliding window. The window size and stride are fixed upon instantiation by the user. This operation can be represented as:</p> \\[ f_{i} = \\text{F}(x_{i - w}, \\dots, x_{i - 1}, x_{i}, \\dots, x_{i + w}), \\quad \\forall i \\in \\{w, \\dots, N - w\\} \\] <p>where \\(F\\) represents a feature extractor function, \\(f_{i}\\) represents the \\(i\\)th feature, \\(x_{i}\\) represents the \\(i\\)th element of the input signal, \\(w\\) represents the window size, and \\(N\\) represents the number of elements in the signal.</p> <p>Here's a visual illustration of the above:</p> <p></p> <p>Overflow can occur when the window extends beyond the bounds of the signal. This can be handled in a number of ways. The default behavior is to pad the signal with zeros. However, we provide several other options for handling overflow.</p> <p>We provide some examples below on how to combine the fixed sliding window abstraction with feature extractors to compute features across a signal.</p> <p>             Bases: <code>object</code></p> <p>Represents a 1D sliding window over a time series signal.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.__init__","title":"<code>__init__(window_size, step_size, overflow='pad', padding=0)</code>","text":"<p>Initialize a new 1D sliding window.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>Union[int, int_]</code> <p>The size of the window.</p> required <code>step_size</code> <code>Union[int, int_]</code> <p>The step size of the window.</p> required <code>overflow</code> <code>str</code> <p>The method to take when there is an overflow of the window compared to the signal. Default is <code>pad</code>. Valid methods:</p> <p><code>restrict</code> - Reduces the window to the end of the signal (results in performance degradation due to broken cache lines).</p> <p><code>pad</code> - Pad signal with value passed to argument <code>padding</code>.</p> <p><code>stop</code> - Skips computation of feature over final window that contains overflow.</p> <code>'pad'</code> <code>padding</code> <code>Union[int, float, int_, float_]</code> <p>The value to pad the signal with in the case of an overflow. Default is <code>0</code>.</p> <code>0</code>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.__repr__","title":"<code>__repr__()</code>","text":"<p>Get the string representation of the sliding window.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the sliding window.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.__str__","title":"<code>__str__()</code>","text":"<p>Get the string representation of the sliding window.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the sliding window.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.get_overflow","title":"<code>get_overflow()</code>","text":"<p>Get the overflow method.</p> <p>Returns:</p> Type Description <code>str</code> <p>The overflow method.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.get_overflow_methods","title":"<code>get_overflow_methods()</code>","text":"<p>Get the overflow methods supported.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of supported overflow methods.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.get_padding","title":"<code>get_padding()</code>","text":"<p>Get the padding value.</p> <p>Returns:</p> Type Description <code>Union[int, float, int_, float_]</code> <p>The padding value.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.get_step_size","title":"<code>get_step_size()</code>","text":"<p>Get the step size.</p> <p>Returns:</p> Type Description <code>Union[int, int_]</code> <p>The step size.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.get_window_size","title":"<code>get_window_size()</code>","text":"<p>Get the window size.</p> <p>Returns:</p> Type Description <code>Union[int, int_]</code> <p>The window size.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.set_overflow","title":"<code>set_overflow(overflow)</code>","text":"<p>Set the overflow method.</p> <p>Parameters:</p> Name Type Description Default <code>overflow</code> <code>str</code> <p>The overflow method to set.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the overflow method is not supported.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.set_padding","title":"<code>set_padding(padding)</code>","text":"<p>Set the padding value.</p> <p>Parameters:</p> Name Type Description Default <code>padding</code> <code>Union[int, float, int_, float_]</code> <p>The padding value to set.</p> required"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.set_step_size","title":"<code>set_step_size(step_size)</code>","text":"<p>Set the step size.</p> <p>Parameters:</p> Name Type Description Default <code>step_size</code> <code>Union[int, int_]</code> <p>The step size.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the step size is not an integer.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.set_window_size","title":"<code>set_window_size(window_size)</code>","text":"<p>Set the window size.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>Union[int, int_]</code> <p>The window size.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the window size is not an integer.</p>"},{"location":"api/core/fixed_window/#autonfeat.core.SlidingWindow.use","title":"<code>use(transform)</code>","text":"<p>Use a transform function to transform each window.</p> <p>Parameters:</p> Name Type Description Default <code>transform</code> <code>Callable[[ndarray], Union[float_, int_]]</code> <p>The transformation to apply to the signal.</p> required <p>Returns:</p> Type Description <code>Callable[[ndarray], ndarray]</code> <p>A function that applies the transformation to the signal using the sliding window.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the transform is not callable.</p>"},{"location":"api/core/fixed_window/#examples","title":"Examples","text":""},{"location":"api/core/fixed_window/#problem_setup","title":"Problem Setup","text":"<p>Consider the following example with signal \\(x\\), window \\(W\\) and feature extractor \\(F\\):</p> <p>\\(t = \\left[0, \\dots, 10\\right]\\)</p> <p>\\(x = \\sin(2t) + \\cos(3t) + \\sin(5t) + \\cos(7t) + \\exp(-t / 5)\\)</p> <p>\\(W_{size} = 50\\)</p> <p>\\(W_{stride} = 25\\)</p> <p>\\(F = \\text{mean}\\)</p> <pre><code>import numpy as np\nimport autonfeat as aft\n# Setup the signal\nt = np.linspace(0, 10, 1000)\nsignal = np.sin(2 * t) + np.cos(3 * t) + np.sin(5 * t) + np.cos(7 * t) + np.exp(-t / 5)\n</code></pre>"},{"location":"api/core/fixed_window/#setup_sliding_window_and_feature_extractor","title":"Setup Sliding Window and Feature Extractor","text":"<pre><code># Setup the sliding window\nwindow_size = 50\nstep_size = 25\nsliding_window = aft.SlidingWindow(window_size=window_size, step_size=step_size)\n# Setup the feature extractor\nfeature_extractor = aft.MeanTransform()\n# Get the featurizer object\nfeaturizer = sliding_window.use(feature_extractor)\n</code></pre>"},{"location":"api/core/fixed_window/#extract_features","title":"Extract Features","text":"<pre><code># Extract features\nfeatures = featurizer(signal)\nprint(features)\n</code></pre> <p>We can view the following operation below:</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/core/preprocess/","title":"Preprocess","text":""},{"location":"api/core/preprocess/#preprocess","title":"Preprocess","text":"<p>The <code>Preprocess</code> class is a core building block in <code>AutonFeat</code>. This enables users to define custom preprocessors that can be applied to the signal before extracting features.</p> <p>             Bases: <code>object</code></p> <p>Represents a preprocessor to apply to a signal.</p>"},{"location":"api/core/preprocess/#autonfeat.core.Preprocess.__call__","title":"<code>__call__(signal, *args, **kwargs)</code>","text":"<p>Apply the preprocessor to the signal provided.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The signal window to apply the preprocessor to.</p> required <code>*args</code> <code>Any</code> <p>Additional arguments to pass to the preprocessor.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the preprocessor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The preprocessed signal.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the preprocessor is not implemented.</p>"},{"location":"api/core/preprocess/#autonfeat.core.Preprocess.__init__","title":"<code>__init__(name='Not specified')</code>","text":"<p>Initialize a new preprocessor.</p>"},{"location":"api/core/preprocess/#autonfeat.core.Preprocess.__repr__","title":"<code>__repr__()</code>","text":"<p>Get the string representation of the preprocessor.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the preprocessor.</p>"},{"location":"api/core/preprocess/#autonfeat.core.Preprocess.__str__","title":"<code>__str__()</code>","text":"<p>Get the string representation of the preprocessor.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the preprocessor.</p>"},{"location":"api/core/preprocess/#autonfeat.core.Preprocess.get_name","title":"<code>get_name()</code>","text":"<p>Get the name of the preprocessor.</p> <p>Returns:</p> Type Description <code>str</code> <p>The name of the preprocessor.</p>"},{"location":"api/core/preprocess/#autonfeat.core.Preprocess.set_name","title":"<code>set_name(name)</code>","text":"<p>Set the name of the preprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The new name of the preprocessor.</p> required"},{"location":"api/core/preprocess/#examples","title":"Examples","text":"<p>In this example, we define a custom preprocessor that shifts the signal by some <code>delta</code> value.</p>"},{"location":"api/core/preprocess/#define_custom_preprocessor","title":"Define Custom Preprocessor","text":"<p>We define a custom preprocessor that performs this computation in the following way.</p> <pre><code>import numpy as np\nfrom typing import Union, Callable\nfrom autonfeat.core import Preprocess\nclass DeltaPreprocessor(Preprocess):\n\"\"\"\n    Preprocess the signal by shifting the `signal` by some `delta` value.\n    \"\"\"\ndef __init__(self, name: str = \"Delta\") -&gt; None:\nsuper().__init__(name=name)\ndef __call__(self, signal: np.ndarray, delta: Union[int, float, np.int_, np.float_], where: Callable[[Union[int, float, np.int_, np.float_]], Union[bool, np.bool_]] = lambda x: not np.isnan(x)) -&gt; np.ndarray:\nwhere_fn = np.vectorize(where)\n# Compute mask and multiply by distribution shift along axis\nmask = where_fn(x)\nshift = mask * delta\nreturn x - shift\n</code></pre>"},{"location":"api/core/preprocess/#apply_custom_preprocessor","title":"Apply Custom Preprocessor","text":"<p>The preprocessor can then be applied to a signal \\(x\\) as follows:</p> <pre><code># Define the signal\nx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n# Define the delta\ndelta = 1\ndelta_preprocessor = DeltaPreprocessor()\n# Apply the preprocessor\nprocessed_signal = delta_preprocessor(x, delta=delta)\n# See the result\nprint(processed_signal)\n</code></pre> <pre><code>[0 1 2 3 4 5 6 7 8]\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/core/transform/","title":"Transform","text":""},{"location":"api/core/transform/#transform","title":"Transform","text":"<p>One of the core building blocks of <code>AutonFeat</code> is the <code>Transform</code> abstraction. This enables users to define custom featurizers that can be applied to the sliding window intervals and is how we implement the build-in feature extractors. </p> <p>             Bases: <code>object</code></p> <p>Represents a transformation to apply to a signal.</p>"},{"location":"api/core/transform/#autonfeat.core.Transform.__call__","title":"<code>__call__(signal_window, *args, **kwargs)</code>","text":"<p>Apply the transformation to the signal window provided.</p> <p>Parameters:</p> Name Type Description Default <code>signal_window</code> <code>ndarray</code> <p>The signal window to transform.</p> required <code>*args</code> <code>Any</code> <p>Additional arguments to pass to the transformation.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the transformation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[float_, int_]</code> <p>A scalar value representing the transformation of the signal.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the transformation is not implemented.</p>"},{"location":"api/core/transform/#autonfeat.core.Transform.__init__","title":"<code>__init__(name='Not specified')</code>","text":"<p>Initialize a new transformation.</p>"},{"location":"api/core/transform/#autonfeat.core.Transform.__repr__","title":"<code>__repr__()</code>","text":"<p>Get the string representation of the transformation.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the transformation.</p>"},{"location":"api/core/transform/#autonfeat.core.Transform.__str__","title":"<code>__str__()</code>","text":"<p>Get the string representation of the transformation.</p> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the transformation.</p>"},{"location":"api/core/transform/#autonfeat.core.Transform.get_name","title":"<code>get_name()</code>","text":"<p>Get the name of the transformation.</p> <p>Returns:</p> Type Description <code>str</code> <p>The name of the transformation.</p>"},{"location":"api/core/transform/#autonfeat.core.Transform.set_name","title":"<code>set_name(name)</code>","text":"<p>Set the name of the transformation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The new name of the transformation.</p> required"},{"location":"api/core/transform/#examples","title":"Examples","text":"<p>In the below example, we show how to define a custom featurizer that computes the mean of the signal.</p>"},{"location":"api/core/transform/#define_featurizer_function","title":"Define Featurizer Function","text":"<p>For ease of use, we define a function that computes the mean of the signal.</p> <pre><code>import numpy as np\ndef mean_function(x):\nreturn np.mean(x)\n</code></pre>"},{"location":"api/core/transform/#define_transform","title":"Define Transform","text":"<p>Use the <code>Transform</code> abstraction to define the featurizer.</p> <pre><code>import numpy as np\nfrom typing import Callable, Union\nfrom autonfeat.core import Transform\nclass MeanTransform(Transform):\ndef __init__(self, name: str = \"Mean\") -&gt; None:\nsuper().__init__(name=name)\ndef __call__(self, signal_window: np.ndarray, where: Callable[[Union[int, float, np.int_, np.float_]], Union[bool, np.bool_]] = lambda x: not np.isnan(x)) -&gt; Union[np.float_, np.int_]:\nwhere_fn = np.vectorize(pyfunc=where)\nfiltered_signal_window = signal_window[where_fn(signal_window)]\nreturn mean_function(filtered_signal_window)\n</code></pre>"},{"location":"api/core/transform/#apply_transform","title":"Apply Transform","text":"<p>Using the <code>SlidingWindow</code> abstraction, we can apply the transform to the sliding window intervals.</p> <pre><code>import autonfeat as aft\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Create transform\ntf = MeanTransform()\n# Get featurizer\nfeaturizer = window.use(tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(window)\nprint(tf)\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/approx_entropy/","title":"approximate entropy","text":""},{"location":"api/functional/approx_entropy/#approximate_entropy_function","title":"Approximate Entropy Function","text":"<p>The approximate entropy function computes the approximate entropy of a window. When combined with the <code>SlidingWindow</code> abstraction, the approximate entropy function can be used to compute the <code>approximate entropy</code> feature of a time series. It is used to quantify the amount of regularity and the unpredictability signals. Approximate entropy measures the likelihood that similar patterns of observations will not be followed by these similar patterns, therefore a time-series signal that exhibits seasonality or other kinds of repetitive patterns will have a relatively small approximate entropy whereas signals without such a repetitive nature will exhibit a high value of approximate entropy [1]. It is defined as:</p> \\[ ApEn(m, r) = \\phi_{m}(r) - \\phi_{m+1}(r) \\] \\[ \\phi_{m}(r) = \\frac{1}{N-m+1} \\sum_{i=1}^{N-m+1} \\ln C_m^i(r) \\] \\[ C_m^i(r) = \\frac{1}{N-m+1} \\sum_{j=1}^{N-m+1} \\Theta(r - ||x_{i+j-1} - x_{j}||) \\] <p>where \\(m\\) is the embedding dimension, \\(r\\) is the tolerance, \\(N\\) is the length of the signal, \\(x_i\\) is the \\(i^{th}\\) sample of the signal, and \\(\\Theta\\) is the Heaviside step function.</p> <p>Compute the approximate entropy of the values in <code>x</code> where <code>where</code> is <code>True</code>. It used to quantify the amount of regularity and the unpredictability of fluctuations in the signal.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The signal to find the approximate entropy of.</p> required <code>m</code> <code>Union[int, int_]</code> <p>The length of the template vector.</p> required <code>r</code> <code>Union[int, int_]</code> <p>The tolerance.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The approximate entropy of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p> References <p>Approximate Entropy - https://en.wikipedia.org/wiki/Approximate_entropy</p>"},{"location":"api/functional/approx_entropy/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.approx_entropy_tf)\n# Get features\nfeatures = featurizer(x, m=2, r=0.2)\n# Print features\nprint(features)\n</code></pre>"},{"location":"api/functional/approx_entropy/#references","title":"References","text":"<p>[1] https://en.wikipedia.org/wiki/Approximate_entropy</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/cross_entropy/","title":"cross entropy","text":""},{"location":"api/functional/cross_entropy/#cross_entropy_function","title":"Cross Entropy Function","text":"<p>The cross-entropy function computes the cross entropy between two discrete probability distributions. The cross entropy is defined as:</p> \\[ H(p, q) = -\\sum_{x} p(x) \\log q(x) \\] <p>where \\(p\\) and \\(q\\) are the two probability distributions. The cross entropy is a measure of the difference between two probability distributions. The cross entropy is zero if and only if the two distributions are identical. The cross entropy is always non-negative i.e. \\(H(p, q) \\geq 0\\).</p> <p>Compute the cross entropy of the values in <code>pk</code> with respect to <code>qk</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pk</code> <code>ndarray</code> <p>A discrete probability distribution.</p> required <code>qk</code> <code>ndarray</code> <p>A second discrete probability distribution.</p> required <code>base</code> <code>Optional[Union[int, int_]]</code> <p>The base of the logarithm used to compute the entropy. Default is <code>None</code> which means that the natural logarithm is used.</p> <code>None</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The cross-entropy of the values in <code>pk</code> with respect to <code>qk</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/functional/cross_entropy/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx1 = np.random.rand(n_samples)\nx2 = np.random.rand(n_samples)\n# Sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.cross_entropy_tf)\n# Get features\nfeatures = featurizer(x1, x2)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/data_density/","title":"data density","text":""},{"location":"api/functional/data_density/#data_density_function","title":"Data Density Function","text":"<p>The data density function computes the ratio of valid values in a sliding window to the total number of values in the window. See <code>n-valid</code> for more details on how valid values are computed. It can be coupled with the <code>SlidingWindow</code> abstraction to compute the <code>data density</code> feature of a time series. It can be defined as:</p> \\[ \\text{density} = \\frac{N_{valid}}{N_{total}} \\] <p>where \\(N_{valid}\\) is the number of valid values in a window \\(W\\) and \\(N_{total}\\) is the total number of values in \\(W\\).</p> <p>Compute the data density of the array <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the data density of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The data density of measurements in <code>x</code>.</p> <p>Raises:</p> Type Description <code>DivideByZeroError</code> <p>If <code>x</code> is empty.</p>"},{"location":"api/functional/data_density/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.data_density_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/data_sparsity/","title":"data sparsity","text":""},{"location":"api/functional/data_sparsity/#data_sparsity_function","title":"Data Sparsity Function","text":"<p>The data sparsity function computes the ratio of invalid values in a sliding window to the total number of values in the window. See <code>n-valid</code> for more details on how valid and invalid values are computed. It can be coupled with the <code>SlidingWindow</code> abstraction to compute the <code>data sparsity</code> feature of a time series. It can be defined as:</p> \\[ \\text{sparsity} = \\frac{N_{invalid}}{N_{total}} \\] <p>where \\(N_{invalid}\\) is the number of invalid values in a window \\(W\\) and \\(N_{total}\\) is the total number of values in \\(W\\).</p> <p>Compute the data sparsity of the array <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the data sparsity of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The data sparsity of measurements in <code>x</code>.</p> <p>Raises:</p> Type Description <code>DivideByZeroError</code> <p>If <code>x</code> is empty.</p>"},{"location":"api/functional/data_sparsity/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.data_sparsity_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/entropy/","title":"entropy","text":""},{"location":"api/functional/entropy/#entropy_function","title":"Entropy Function","text":"<p>The entropy function computes the entropy of a distribution. The entropy is a measure of the uncertainty of a random variable. The entropy of a distribution is defined as:</p> \\[ H(X) = -\\sum_{i=1}^{n} p(x_i) \\log p(x_i) \\] <p>where \\(p(x_i)\\) is the probability of the \\(i\\)-th outcome. The entropy is maximized when all outcomes are equally likely. The entropy is zero when the distribution is deterministic.</p> <p>We can use the entropy function to compute the entropy of a single discrete probability distribution using Shannon Entropy. We can also use the entropy function to compute the relative entropy between two discrete probability distributions. This is also called the Kullback-Leibler (KL) divergence. This is defined as:</p> \\[ D_{KL}(p||q) = H(p, q) = \\sum_{x} p(x) \\log \\frac{p(x)}{q(x)} \\] <p>where \\(p\\) and \\(q\\) are the two probability distributions. The relative entropy is zero if and only if the two distributions are identical. The relative entropy is always non-negative.</p> <p>Compute the entropy of the values in <code>pk</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pk</code> <code>ndarray</code> <p>The discrete probability distribution to find the entropy of.</p> required <code>qk</code> <code>Optional[numpy.ndarray]</code> <p>The second discrete probability distribution to find the relative entropy with.</p> <code>None</code> <code>base</code> <code>Optional[Union[int, int_]]</code> <p>The base of the logarithm used to compute the entropy. Default is <code>None</code> which means that the natural logarithm is used.</p> <code>None</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The entropy of the values in <code>pk</code> optionally with respect to <code>qk</code> (relative entropy) where <code>where</code> is <code>True</code>.</p>"},{"location":"api/functional/entropy/#examples","title":"Examples","text":""},{"location":"api/functional/entropy/#shannon_entropy","title":"Shannon Entropy","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.randint(0, 10, n_samples)\n# Sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.entropy_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre>"},{"location":"api/functional/entropy/#kl_divergence","title":"KL Divergence","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx1 = np.random.rand(n_samples)\nx2 = np.random.rand(n_samples)\n# Sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.entropy_tf)\n# Get features\nfeatures = featurizer(x1, x2)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/iqr/","title":"iqr","text":""},{"location":"api/functional/iqr/#inter-quartile_range_function","title":"Inter-Quartile Range Function","text":"<p>The inter-quartile range function computes the inter-quartile range of the data in a sliding window. The inter-quartile range is the difference between the \\(75^{th}\\) and \\(25^{th}\\) percentiles of the data and can be defined as:</p> \\[ \\text{IQR} = \\text{Q3} - \\text{Q1} \\] <p>where \\(\\text{Q1}\\) and \\(\\text{Q3}\\) are the \\(25^{th}\\) and \\(75^{th}\\) percentiles of the data, respectively.</p> <p>Compute the inter-quartile range of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the IQR of.</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantiles. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The IQR of the values in <code>x</code>.</p>"},{"location":"api/functional/iqr/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.iqr_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/kurtosis/","title":"kurtosis","text":""},{"location":"api/functional/kurtosis/#kurtosis_function","title":"Kurtosis Function","text":"<p>The kurtosis function computes the kurtosis of a window. When combined with the SlidingWindow abstraction, the kurtosis function can be used to compute the <code>kurtosis</code> feature of a time series. The kurtosis is defined as:</p> \\[ \\kappa = \\begin{cases} \\frac{m_4}{m_2^2} - 3 &amp; \\text{Fisher} \\\\ \\frac{m_4}{m_2^2} &amp; \\text{Pearson} \\end{cases} \\] <p>where \\(m_2\\) and \\(m_4\\) are the second and fourth central moments, respectively. They are defined as:</p> \\[ m_2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2 \\] \\[ m_4 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^4 \\] <p>where \\(N\\) is the number of samples in the window and \\(\\bar{x}\\) is the mean of the window.</p> <p>Compute the krutosis of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p> <p>The krutosis is a measure of the \"tailedness\" of a distribution. It is defined as the fourth standardized moment of a distribution, and is calculated as:</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the krutosis of.</p> required <code>fisher</code> <code>Union[bool, bool_]</code> <p>Whether to use Fisher's definition of kurtosis i.e. subtract 3 from the result. Default is <code>True</code>. If <code>False</code>, the result is the Pearson's definition of kurtosis.</p> <code>True</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The krutosis of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/functional/kurtosis/#examples","title":"Examples","text":""},{"location":"api/functional/kurtosis/#fisher_kurtosis","title":"Fisher Kurtosis","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.kurtosis_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre>"},{"location":"api/functional/kurtosis/#pearson_kurtosis","title":"Pearson Kurtosis","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.kurtosis_tf)\n# Get features\nfeatures = featurizer(x, fisher=False)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/max/","title":"max","text":""},{"location":"api/functional/max/#max_function","title":"Max Function","text":"<p>The max function computes the max of a window. When combined with the <code>SlidingWindow</code> abstraction, the max function can be used to compute the <code>max</code> feature of a time series. The max is defined as:</p> \\[ \\text{max}(x) = \\max_{i=1}^n x_i \\] <p>where \\(x\\) is a vector of length \\(n\\).</p> <p>Compute the max of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the max of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <code>initial</code> <code>Union[int, float, int_, float_]</code> <p>The initial value to use when computing the max. Default is <code>-np.inf</code>.</p> <code>-inf</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The max of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/functional/max/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.max_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/mean/","title":"mean","text":""},{"location":"api/functional/mean/#mean_function","title":"Mean Function","text":"<p>The mean function computes the mean of a signal. Mean is often used as a summary statistic for a signal. Using the <code>SlidingWindow</code> abstraction, the mean can be computed over a sliding window of the signal to be produce a set of features that can be used for a downstream task.</p>"},{"location":"api/functional/mean/#autonfeat.functional.mean.mean_tf","title":"<code>mean_tf(x, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the mean of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the mean of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The mean of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/functional/mean/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.mean)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/median/","title":"median","text":""},{"location":"api/functional/median/#median_function","title":"Median Function","text":"<p>The median function computes the median of a window. When combined with the <code>SlidingWindow</code> abstraction, the median function can be used to compute the <code>median</code> feature of a time series. The median is defined as: (write the formula as two cases for even and odd length vectors and index with i for each case)</p> \\[ \\text{median}(x) = \\begin{cases} 0.5 \\cdot (x_{\\lfloor n/2 \\rfloor} + x_{\\lceil n/2 \\rceil}) &amp; \\text{if $n$ is even} \\\\ x_{\\lfloor n/2 \\rfloor} &amp; \\text{if $n$ is odd} \\end{cases} \\] <p>where \\(x\\) is a vector of length \\(n\\).</p> <p>Compute the median of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the median of.</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantile. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The median of the values in <code>x</code>.</p>"},{"location":"api/functional/median/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.median_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/min/","title":"min","text":""},{"location":"api/functional/min/#max_function","title":"Max Function","text":"<p>The min function computes the min of a window. When combined with the <code>SlidingWindow</code> abstraction, the min function can be used to compute the <code>min</code> feature of a time series. The min is defined as:</p> \\[ \\text{min}(x) = \\min_{i=1}^n x_i \\] <p>where \\(x\\) is a vector of length \\(n\\).</p> <p>Compute the min of the values in <code>x</code> where <code>where</code> is True.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the min of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <code>initial</code> <code>Union[int, float, int_, float_]</code> <p>The initial value to use when computing the min. Default is <code>np.inf</code>.</p> <code>inf</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The min of the values in <code>x</code> where <code>where</code> is True.</p>"},{"location":"api/functional/min/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.min_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/n_valid/","title":"n-valid","text":""},{"location":"api/functional/n_valid/#n-valid_function","title":"N-Valid Function","text":"<p>Compute the number of valid measurements in a sliding window. A valid measurement by default is defined as a measurement that is not <code>np.nan</code>, however this can be altered by passing a validity function to the argument <code>where</code>. The validity function should take a single argument, the measurement, and return <code>True</code> if the measurement is valid, and <code>False</code> otherwise. The function can be defined as:</p> \\[ \\mathbb{1}_{\\text{valid}}(x_i) = \\begin{cases} 1 &amp; \\text{if } x_i \\text{ is valid} \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\] <p>where \\(x_i\\) is the \\(i\\)-th measurement in the sliding window.</p> \\[ \\text{NValid} = \\sum_{i=1}^n \\mathbb{1}_{\\text{valid}}(x_i) \\] <p>where \\(n\\) is the number of measurements in the sliding window.</p> <p>Compute the number of valid measurements in <code>x</code> where <code>where</code> is <code>True</code> for valid measurements.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the number of valid measurements in.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The number of valid measurements in <code>x</code>.</p>"},{"location":"api/functional/n_valid/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.n_valid_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/quantile/","title":"quantile","text":""},{"location":"api/functional/quantile/#quantile_function","title":"Quantile Function","text":"<p>The quantile function computes the q-th quantile of the data in the sliding window. The quantile is computed using the numpy.quantile function. The function can be combined with the <code>SlidingWindow</code> to compute the quantile of the data in a sliding window. We can use this function to compute the median of the data in a sliding window by setting <code>q=0.5</code>.</p> <p>Compute the q-th quantile of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the q-th quantile of.</p> required <code>q</code> <code>Union[float, float_]</code> <p>The quantile to compute. <code>q</code> belongs to [0, 1].</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantile. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The q-th quantile of the values in <code>x</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>q</code> is not in [0, 1].</p>"},{"location":"api/functional/quantile/#examples","title":"Examples","text":""},{"location":"api/functional/quantile/#25th_percentile","title":"25th percentile","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.quantile_tf)\n# Get features\nfeatures = featurizer(x, q=0.25)\n# Print features\nprint(features)\n</code></pre>"},{"location":"api/functional/quantile/#median","title":"Median","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.quantile_tf)\n# Get features\nfeatures = featurizer(x, q=0.5)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/range/","title":"range","text":""},{"location":"api/functional/range/#range_function","title":"Range Function","text":"<p>The range function computes the range of the data in the sliding window. When paired with the <code>SlidingWindow</code> abstraction, one can compute the range over a sliding window across a time series. The range is computed as the difference between the maximum and minimum values in the window and can be defined as:</p> \\[ \\text{range} = \\max(x) - \\min(x) \\] <p>where \\(x\\) is the data in the sliding window.</p> <p>Compute the range of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the range of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The range of the values in <code>x</code>.</p>"},{"location":"api/functional/range/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.range_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/sample_entropy/","title":"sample entropy","text":""},{"location":"api/functional/sample_entropy/#sample_entropy_function","title":"Sample Entropy Function","text":"<p>The sample entropy function computes the sample entropy of a window. When combined with the <code>SlidingWindow</code> abstraction, the sample entropy function can be used to compute the <code>sample entropy</code> feature of a time series. Sample entropy is a measure of the complexity of the signal [1]. It is a modification of the approximate entropy (ApEn) algorithm which can be found here. It is defined as:</p> \\[ \\text{Sample Entropy} = -\\log\\left(\\frac{A}{B}\\right) \\] <p>where \\(A\\) is the number of matches for template vectors of length \\(m\\) and \\(B\\) is the number of matches for template vectors of length \\(m + 1\\). A match is defined as a template vector \\(x_{m_i}\\) that is close to another template vector \\(x_{m_j}\\) in the sense that the maximum absolute difference between their corresponding scalar elements is less than or equal to a threshold \\(r\\).</p> <p>Compute the sample entropy of the values in <code>x</code> where <code>where</code> is <code>True</code>. This is a measure of the complexity of a signal.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The signal to find the sample entropy of.</p> required <code>m</code> <code>Union[int, int_]</code> <p>The length of the template vector.</p> required <code>r</code> <code>Union[int, int_]</code> <p>The tolerance.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The sample entropy of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p> References <p>Sample Entropy -https://en.wikipedia.org/wiki/Sample_entropy</p>"},{"location":"api/functional/sample_entropy/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.sample_entropy_tf)\n# Get features\nfeatures = featurizer(x, m=2, r=0.2)\n# Print features\nprint(features)\n</code></pre>"},{"location":"api/functional/sample_entropy/#references","title":"References","text":"<p>[1] https://en.wikipedia.org/wiki/Sample_entropy</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/skewness/","title":"skewness","text":""},{"location":"api/functional/skewness/#skewness_function","title":"Skewness Function","text":"<p>The skew function computes the skewness of a window. When combined with the <code>SlidingWindow</code> abstraction, the skew function can be used to compute the <code>skew</code> feature of a time series. The skewness is defined as:</p> \\[ \\gamma = \\frac{m_3}{m_2^{3/2}} \\] <p>We use this and correct for statistical bias. The Fisher-Pearson standardized moment coefficient is defined as:</p> \\[ \\Gamma = \\gamma \\sqrt{\\frac{N(N-1)}{N-2}} \\] <p>where \\(m_2\\) and \\(m_3\\) are the second and third central moments, respectively. They are defined as:</p> \\[ m_2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2 \\] \\[ m_3 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^3 \\] <p>where \\(N\\) is the number of samples in the window and \\(\\bar{x}\\) is the mean of the window.</p> <p>Compute the skewness of the values in <code>x</code> where <code>where</code> is <code>True</code>. The skewness is computed using the Fisher-Pearson standardized coefficient of skewness. The skewness is only computed for valid values i.e. values where <code>where</code> is <code>True</code>. The skewness computed is corrected for statistical bias.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the skewness of.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The skewness of the values in <code>x</code> where <code>where</code> is <code>True</code>.</p>"},{"location":"api/functional/skewness/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.skewness_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/std/","title":"std","text":""},{"location":"api/functional/std/#standard_deviation_function","title":"Standard Deviation Function","text":"<p>The standard deviation function computes the standard deviation of a window. When combined with the <code>SlidingWindow</code> abstraction, the standard deviation function can be used to compute the <code>std</code> feature of a time series. The standard deviation is defined as:</p> \\[ \\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2} \\] <p>where \\(x_i\\) is the \\(i\\)-th element of the window, \\(n\\) is the number of elements in the window, and \\(\\mu\\) is the mean of the window.</p> <p>Compute the standard deviation of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the median of.</p> required <code>ddof</code> <code>Union[int, int_]</code> <p>The delta degrees of freedom. Default is <code>0</code>. See <code>numpy.std</code> for more information.</p> <code>0</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The standard deviation of the values in <code>x</code>.</p>"},{"location":"api/functional/std/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.std_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/functional/var/","title":"var","text":""},{"location":"api/functional/var/#variance_function","title":"Variance Function","text":"<p>The variance function computes the variance of a window. When combined with the <code>SlidingWindow</code> abstraction, the variance function can be used to compute the <code>var</code> feature of a time series. The variance is defined as:</p> \\[ \\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2 \\] <p>where \\(x_i\\) is the \\(i\\)-th element of the window, \\(n\\) is the number of elements in the window, and \\(\\mu\\) is the mean of the window.</p> <p>Compute the variance of the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the variance of.</p> required <code>ddof</code> <code>Union[int, int_]</code> <p>The delta degrees of freedom. Default is <code>0</code>. See <code>numpy.var</code> for more information.</p> <code>0</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The variance of the values in <code>x</code>.</p>"},{"location":"api/functional/var/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nimport autonfeat.functional as F\n# Random data\nn_samples = 100\nx = np.random.rand(n_samples)\n# Create sliding window\nws = 10\nss = 10\nwindow = aft.SlidingWindow(window_size=ws, step_size=ss)\n# Get featurizer\nfeaturizer = window.use(F.var_tf)\n# Get features\nfeatures = featurizer(x)\n# Print features\nprint(features)\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/health/health/","title":"Health","text":"<p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/preprocess/","title":"Preprocessors","text":""},{"location":"api/preprocess/preprocess/#preprocessors","title":"Preprocessors","text":"<p>Data is sometimes not in the right form for a model. Hence, we featurize it. The same applies for a featurizer. Sometimes, data is not in the right form to be featurized. We may observe interesting properties emerge when we explore features in different domains. This is where the preprocess sub-module is helpful! We provide a wide variety of preprocessors to act as a bridge between the raw data and the featurizer.</p>"},{"location":"api/preprocess/preprocess/#preprocess_submodules","title":"Preprocess Submodules","text":"Submodule Description <code>autonfeat.preprocess</code> Contains preprocessing featurizers in the form of modules (classes). <code>autonfeat.preprocess.functional</code> Contains preprocessing featurizers in the form of functions."},{"location":"api/preprocess/preprocess/#delta_distribution_shift","title":"Delta Distribution Shift","text":"Feature Description Endpoint Delta Delta from a value and the rest of the signal <code>DeltaPreprocessor</code> Delta Mean Delta from the mean of the signal <code>DeltaMeanPreprocessor</code> Delta Median Delta from the median of the signal <code>DeltaMedianPreprocessor</code> Delta Max Delta from the maximum value of the signal <code>DeltaMaxPreprocessor</code> Delta Min Delta from the minimum value of the signal <code>DeltaMinPreprocessor</code> Delta Std Delta from the standard deviation of the signal <code>DeltaStdPreprocessor</code> Delta Var Delta from the variance of the signal <code>DeltaVarPreprocessor</code> Delta Quantile Delta from the quantile of the signal <code>DeltaQuantilePreprocessor</code>"},{"location":"api/preprocess/preprocess/#frequency_domain","title":"Frequency Domain","text":"Feature Description Endpoint DFT 1D Discrete Fourier Transform of the signal <code>DFTPreprocessor</code> Power Spectrum Power spectrum of the signal <code>PowerSpectrumPreprocessor</code>"},{"location":"api/preprocess/preprocess/#signal_manipulation","title":"Signal Manipulation","text":"Feature Description Endpoint Lag Lag the signal by some amount <code>LagPreprocessor</code>"},{"location":"api/preprocess/preprocess/#functional_form","title":"Functional Form","text":"<p>A functional form for each of the transforms above is also provided for convenience. Check out the <code>autonfeat.preprocess.functional</code> sub-module for more details.</p>"},{"location":"api/preprocess/preprocess/#custom_preprocessors","title":"Custom Preprocessors","text":"<p><code>AutonFeat</code> makes it easy to design custom preprocessors by inheriting from the <code>Preprocess</code> class that is a part of the library's core engine. In this example, we show how to implement a <code>DeltaPreprocessor</code> that shifts a signal by some \\(\\delta\\) value.</p> <pre><code>import numpy as np\nfrom typing import Union, Callable\nfrom autonfeat.core import Preprocess\nclass DeltaPreprocessor(Preprocess):\ndef __init__(self, name: str = \"Delta\") -&gt; None:\nsuper().__init__(name=name)\ndef __call__(self, signal: np.ndarray, delta: Union[int, float, np.int_, np.float_], where: Callable[[Union[int, float, np.int_, np.float_]], Union[bool, np.bool_]] = lambda x: not np.isnan(x)) -&gt; np.ndarray:\nwhere_fn = np.vectorize(where)\nmask = where_fn(x)\nshift = mask * delta\nreturn x - shift\n</code></pre> <p>The preprocessor can then be applied to a signal \\(x\\) as follows:</p> <pre><code># Define the signal\nx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n# Define the delta\ndelta = 1\ndelta_preprocessor = DeltaPreprocessor()\n# Apply the preprocessor\nprocessed_signal = delta_preprocessor(x, delta=delta)\n# See the result\nprint(processed_signal)\n</code></pre> <pre><code>[0 1 2 3 4 5 6 7 8]\n</code></pre> <p>See this for more examples on how to use preprocessors in <code>AutonFeat</code>.</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/delta_max_preprocessor_fn/","title":"delta max","text":""},{"location":"api/preprocess/functional/delta_max_preprocessor_fn/#delta_max_preprocessor","title":"Delta Max Preprocessor","text":"<p>The delta max preprocessor function shifts the input signal by the max of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\max({x}), \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>delta preprocessor</code> function. For more on how we compute the max of a signal, check out <code>max</code> function.</p> <p>Preprocess the signal <code>x</code> by shifting each element of <code>x</code> by the maximum of <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the difference from its maximum.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <code>initial</code> <code>Union[int, float, int_, float_]</code> <p>The initial value for the maximum. Default is <code>-np.inf</code>.</p> <code>-inf</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/delta_max_preprocessor_fn/#examples","title":"Examples","text":"<p>Consider the following example. We generate a sound wave with a frequencey of 500Hz. The sound wave may contain magnitudes that are not safe for the human ear. We can apply the delta max preprocessor function to shift the signal such that it falls within a safe range.</p>"},{"location":"api/preprocess/functional/delta_max_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\n# Create a random signal\ntime = np.linspace(0, 10, 1000)\nfrequency = 500  # Frequency of the signal in Hz\nsound_wave = np.sin(2 * np.pi * frequency * time) + 0.5 * np.sin(2 * np.pi * 2 * frequency * time) + 0.25 * np.sin(2 * np.pi * 3 * frequency * time)\n# Shift the sound wave by the peak value to ensure safe listening levels\n# if we define a safe listening level as 0.5\nsafe_level = 0.5\nsafe_sound = PF.delta_max_tf(sound_wave) + safe_level\n</code></pre>"},{"location":"api/preprocess/functional/delta_max_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<pre><code>import matplotlib.pyplot as plt\n# Plot the original signal and the shifted signal\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(time, sound_wave, label='Original Signal')\nax.plot(time, safe_sound, label='Shifted Signal')\nax.axhline(y=safe_level, color='red', linestyle='--', linewidth=2)\nax.annotate('Safe Listening Level', xy=(0, safe_level), xytext=(0.5, safe_level + 0.1), arrowprops=dict(facecolor='black', shrink=0.05))\nax.set_xlabel('Time (s)')\nax.set_ylabel('Amplitude')\nax.set_title('Sound Wave')\nax.legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/delta_mean_preprocessor_fn/","title":"delta mean","text":""},{"location":"api/preprocess/functional/delta_mean_preprocessor_fn/#delta_mean_preprocessor","title":"Delta Mean Preprocessor","text":"<p>The delta mean preprocessor function shifts the input signal by the mean of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\mu_{x}, \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>delta preprocessor</code> function. For more on how we compute the mean of a signal, check out <code>mean</code> function.</p> <p>Preprocess the signal <code>x</code> by shifting each element of <code>x</code> by the mean of <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the difference from its mean.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/delta_mean_preprocessor_fn/#examples","title":"Examples","text":""},{"location":"api/preprocess/functional/delta_mean_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<p>We sample from a normal distribution with mean \\(\\mu = 10\\) and standard deviation \\(\\sigma = 1\\). We then apply the delta mean preprocessor function to shift the distribution to be centered at zero.</p> <p>A 1D normal distribution centered at \\(\\mu\\) with standard deviation \\(\\sigma\\) is defined as:</p> \\[ f(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}} \\] <pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\n# Parameters for the normal distribution\nmu = 50      # Mean\nsigma = 1   # Standard deviation\nn_samples = 10000\n# Generate random samples from the normal distribution\nsamples = np.random.normal(mu, sigma, n_samples)\n# Preprocess signal\ntransformed_samples = PF.delta_mean_tf(samples)\n</code></pre>"},{"location":"api/preprocess/functional/delta_mean_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<p>We can observe a shift in the distribution of the signal after applying the delta mean preprocessor function. The distribution is shifted to be centered at zero.</p> <pre><code>import matplotlib.pyplot as plt\n# Compute the range and pdf for plotting\nx = np.linspace(mu - 4 * sigma, mu + 4 * sigma, n_samples)\npdf = 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-(x - mu)**2 / (2 * sigma**2))\n# Compute the expected range and pdf for plotting\nx_shifted = x - mu\ntransformed_pdf = 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-(x_shifted)**2 / (2 * sigma**2))\n# Plot one below the other\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\nax1.hist(samples, bins=50, density=True, alpha=0.7, color='grey')\nax1.plot(x, pdf, color='blue', linewidth=2)\nax1.axvline(x=mu, color='red', linestyle='--', linewidth=2)\nax1.set_xlabel('x')\nax1.set_ylabel('Probability Density')\nax1.set_title('Normal Distribution Centered at {:.2f}'.format(mu))\nax2.hist(transformed_samples, bins=50, density=True, alpha=0.7, color='grey')\nax2.plot(x_shifted, transformed_pdf, color='blue', linewidth=2)\nax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\nax2.set_xlabel('x')\nax2.set_ylabel('Probability Density')\nax2.set_title('Normal Distribution Centered at {:.2f}'.format(0))\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/delta_median_preprocessor_fn/","title":"delta median","text":""},{"location":"api/preprocess/functional/delta_median_preprocessor_fn/#delta_median_preprocessor","title":"Delta Median Preprocessor","text":"<p>The delta median preprocessor function shifts the input signal by the median of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - median({x}), \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>delta preprocessor</code> function. For more on how we compute the median of a signal, check out <code>median</code> function.</p> <p>Preprocess the signal <code>x</code> by shifting each element of <code>x</code> by the median of <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to shift by its median.</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantile. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/delta_median_preprocessor_fn/#examples","title":"Examples","text":"<p>Signal equilization is a common problem in signal processing. The delta median preprocessor function can be used to equilize signals by shifting them by their median. This can be useful for removing the effect of a constant bias in the signal. This is often done in sound engineering when equilizing the sound of different instruments. In the example below, we generate three signals, a guitar signal, a piano signal, and a drums signal. We then apply the delta median preprocessor function to each signal.</p>"},{"location":"api/preprocess/functional/delta_median_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<p>We first generate the signals. Then we perform the equilization by applying the transform to each signal.</p> <pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\n# Generating example signals for each instrument\nnum_samples = 100\ntime = np.linspace(0, 1, num_samples)\nguitar_signal = np.sin(2 * np.pi * 10 * time)  # Guitar signal (higher frequency sine wave)\npiano_signal = np.cos(2 * np.pi * 2 * time)  # Piano signal (cosine wave)\ndrums_signal = np.random.normal(2, 0.5, num_samples)  # Drums signal (random noise with higher mean)\n# Applying the transform to each signal\nguitar_eq = PF.delta_median_tf(guitar_signal)\npiano_eq = PF.delta_median_tf(piano_signal)\ndrums_eq = PF.delta_median_tf(drums_signal)\n</code></pre>"},{"location":"api/preprocess/functional/delta_median_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<p>We can visualize the effect of the transform by plotting the original signals and the shifted signals on the same plot. We can see that the median of each signal is shifted to zero.</p> <pre><code>import matplotlib.pyplot as plt\n# Set up custom line styles\nline_styles = ['-', '--', '-.']\n# Set up custom color palette\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n# Plotting all original signals on one subplot\nplt.figure(figsize=(10, 10))\nplt.subplot(2, 1, 1)\nfor i, signal in enumerate([guitar_signal, piano_signal, drums_signal]):\nplt.plot(time, signal, color=colors[i], linestyle=line_styles[i])\nplt.title('Original Signals')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.legend(['Guitar', 'Piano', 'Drums'])\nplt.grid(True)\n# Plotting all shifted signals on another subplot\nplt.subplot(2, 1, 2)\nfor i, signal in enumerate([guitar_eq, piano_eq, drums_eq]):\nplt.plot(time, signal, color=colors[i], linestyle=line_styles[i])\nplt.title('Shifted Signals')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.legend(['Guitar', 'Piano', 'Drums'])\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <p>As seen in the figure, the drums signal which had a higher mean than the other signals is shifted down by a larger amount than the other signals. In doing so, we have equilized the signals.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/delta_min_preprocessor_fn/","title":"delta min","text":""},{"location":"api/preprocess/functional/delta_min_preprocessor_fn/#delta_min_preprocessor","title":"Delta Min Preprocessor","text":"<p>The delta min preprocessor function shifts the input signal by the max of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\min({x}), \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>delta preprocessor</code> function. For more on how we compute the min of a signal, check out <code>min</code> function.</p> <p>Preprocess the signal <code>x</code> by shifting each element of <code>x</code> by the minimum of <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to shift by its minimum.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <code>initial</code> <code>Union[int, float, int_, float_]</code> <p>The initial value for the minimum. Default is <code>np.inf</code>.</p> <code>inf</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/delta_min_preprocessor_fn/#examples","title":"Examples","text":""},{"location":"api/preprocess/functional/delta_min_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\n# Create a random signal\ntime = np.linspace(0, 10, 1000)\nfrequency = 500  # Frequency of the signal in Hz\nsignal = np.sin(np.exp(np.sin(2 * np.pi * frequency * time)))\n# Shift the signal by the minimum value\nshifted_signal = PF.delta_min_tf(signal)\n</code></pre>"},{"location":"api/preprocess/functional/delta_min_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<pre><code>import matplotlib.pyplot as plt\n# Plot the original signal and the shifted signal\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(time, signal, label='Original Signal')\nax.plot(time, shifted_signal, label='Shifted Signal')\nax.axhline(y=0, color='red', linestyle='--', linewidth=2)\nax.set_xlabel('Time (s)')\nax.set_ylabel('Amplitude')\nax.set_title('Signal')\nax.legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/delta_preprocessor_fn/","title":"delta","text":""},{"location":"api/preprocess/functional/delta_preprocessor_fn/#delta_preprocessor","title":"Delta Preprocessor","text":"<p>The delta preprocessor function shifts the input signal by a fixed amount. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\delta, \\quad \\forall i \\in \\{1, \\dots, N\\}, \\quad \\delta \\in \\mathbb{R} \\] <p>Preprocess the signal by shifting the <code>signal</code> by some <code>delta</code> value.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The signal to preprocess.</p> required <code>delta</code> <code>Union[int, float, int_, float_]</code> <p>The value to shift the signal by.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/delta_preprocessor_fn/#examples","title":"Examples","text":"<p>Consider a system that feeds in to a half-wave rectifier. Half-wave rectifiers are used to remove the negative portion of a signal and are use in many applications such as power supplies and AM radios. The half-wave rectifier is defined as:</p> \\[ y_{i} = \\max(x_{i}, 0) =  \\begin{cases} x_{i}, &amp; \\text{if } x_{i} \\geq 0 \\\\ 0, &amp; \\text{if } x_{i} &lt; 0 \\end{cases} , \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>where \\(x_{i}\\) represents an element of the input signal, \\(y_{i}\\) represents an element of the output signal, and \\(N\\) is the number of elements in the signal. </p> <p>Suppose we want to apply the half-wave rectifer to just the AC part of a signal containing both AC and DC components, we can use the delta preprocessor function to eliminate the DC component.</p>"},{"location":"api/preprocess/functional/delta_preprocessor_fn/#define_signal_hwr_system_and_preprocessor","title":"Define Signal, HWR System, and Preprocessor","text":"<p>Define a signal with the following parameters:</p> \\[ signal_{i} = DC_{offset} + AC_{amp} \\cdot \\sin(2 \\pi \\cdot freq \\cdot time_{i}) \\] <p>\\(DC_{offset} = 5\\) V</p> <p>\\(AC_{amp} = 2\\) V</p> <p>\\(freq = 500\\) Hz</p> <p>\\(N = 1000\\) samples</p> <p>\\(T = 10\\) s</p> <pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\n# Define signal\ntime = np.linspace(0, 10, 1000) # secs\nfreq = 500                      # Hz\ndc_offset = 5                   # V\nac_amp = 2                      # V\nsignal = dc_offset + ac_amp * np.sin(2 * np.pi * freq * time)\n# Define half-wave rectifier\nhalf_wave_rectifier = lambda x_i: np.maximum(x_i, 0)\n</code></pre>"},{"location":"api/preprocess/functional/delta_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<p>Transform the signal by the delta transform preprocessor and apply the half-wave rectifier. This will remove the DC component by setting \\(\\delta = DC_{offset} = 5\\) V.</p> <pre><code>delta = dc_offset # Amount to shift by\n# Preprocess signal\nsignal_transformed = PF.delta_tf(signal, delta=delta)\n# Apply half-wave rectifier\nsystem_output = half_wave_rectifier(signal_transformed)\n</code></pre>"},{"location":"api/preprocess/functional/delta_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<p>Visualize the signal, the transformed signal, and the output of the half-wave rectifier with and without the delta transform preprocessor.</p> <pre><code>import matplotlib.pyplot as plt\n# Plot results\nfig, (ax1, ax2) = plt.subplots(2, 2, figsize=(10, 6))\n# Plot signal and output of half-wave rectifier (before delta transform)\nax1[0].plot(time, signal, label='Signal')\nax1[0].set_xlabel('Time (s)')\nax1[0].set_ylabel('Voltage (V)')\nax1[0].set_title('Original Signal')\nax1[0].grid(True)\nax1[0].legend()\nax1[1].plot(time, half_wave_rectifier(signal), color='orange', label='Output')\nax1[1].set_xlabel('Time (s)')\nax1[1].set_ylabel('Voltage (V)')\nax1[1].set_title('Output of Half-Wave Rectifier (Before Preprocessing)')\nax1[1].grid(True)\nax1[1].legend()\n# Plot signal and output of half-wave rectifier (after delta transform)\nax2[0].plot(time, signal_transformed, label='Signal')\nax2[0].set_xlabel('Time (s)')\nax2[0].set_ylabel('Voltage (V)')\nax2[0].set_title('Signal After Delta Transform')\nax2[0].grid(True)\nax2[0].legend()\nax2[1].plot(time, system_output, color='orange', label='Output')\nax2[1].set_xlabel('Time (s)')\nax2[1].set_ylabel('Voltage (V)')\nax2[1].set_title('Output of Half-Wave Rectifier (After Preprocessing)')\nax2[1].grid(True)\nax2[1].legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p>We can observe how with the help of the delta preprocessor function, shifting the signal by the DC offset of the signal eliminates the DC component of the signal and allows the half-wave rectifier to only act on the AC component of the signal.</p> <p></p>"},{"location":"api/preprocess/functional/delta_preprocessor_fn/#fun_fact","title":"Fun Fact","text":"<p>Half-wave rectifiers are equivalent to a rectified linear unit i.e. the \\(ReLU\\) activation function used in neural networks.</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/delta_quantile_preprocessor_fn/","title":"delta quantile","text":""},{"location":"api/preprocess/functional/delta_quantile_preprocessor_fn/#delta_quantile_preprocessor","title":"Delta Quantile Preprocessor","text":"<p>The delta quantile preprocessor function shifts the input signal by the quantile of the signal. This is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\text{quantile}(x), \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>where \\(x_{i}\\) represents an element of the input signal, \\(x_{shifted_{i}}\\) represents an element of the output signal, and \\(N\\) is the number of elements in the signal.</p> <p>For shifting signals by a custom \\(\\delta\\), see the <code>delta preprocessor</code> function. For more on how we compute the quantile of a signal, check out <code>quantile</code> function.</p> <p>Preprocess the signal <code>x</code> by shifting each element of <code>x</code> by a quantile of <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to shift by its quantile.</p> required <code>q</code> <code>Union[float, float_]</code> <p>The quantile to compute. Must be between 0 and 1.</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantile. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/delta_quantile_preprocessor_fn/#examples","title":"Examples","text":""},{"location":"api/preprocess/functional/delta_quantile_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat.functional as F\nimport autonfeat.functional.preprocess as PF\n# Generate data\nn_samples = 1000\nx = np.random.normal(-5, 5, n_samples)\nq_tile = 0.25 # 25th quantile\n# Preprocess data\nx_shifted = PF.delta_quantile_tf(x, q=q_tile)\n</code></pre>"},{"location":"api/preprocess/functional/delta_quantile_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<pre><code>import matplotlib.pyplot as plt\n# Plot normal and shifted data\noriginal_quantile = F.quantile_tf(x, q_tile)\nshifted_quantile = F.quantile_tf(x_shifted, q_tile)\nplt.figure(figsize=(8, 6))\nplt.plot(x, '.', color='blue', label='Origianl Data')\nplt.axhline(original_quantile, color='red', linestyle='--', linewidth=3, label=f'Original Data 25th quantile = {original_quantile:.2f}')\nplt.plot(x_shifted, '.', color='orange', label='Shifted Data')\nplt.axhline(shifted_quantile, color='green', linestyle='--', linewidth=3, label=f'Shifted Data 25th quantile = {shifted_quantile:.2f}')\nplt.legend()\nplt.title('Delta Quantile Preprocessing')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/delta_std_preprocessor_fn/","title":"delta std","text":""},{"location":"api/preprocess/functional/delta_std_preprocessor_fn/#delta_std_preprocessor","title":"Delta Std Preprocessor","text":"<p>The delta std preprocessor function shifts the input signal by the std of the signal. This is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\sigma_{x}, \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>delta preprocessor</code> function. For more on how we compute the std of a signal, check out <code>std</code> function.</p> <p>Preprocess the signal <code>x</code> by shifting each element of <code>x</code> by the standard deviation of <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to shift by its standard deviation.</p> required <code>ddof</code> <code>Union[int, int_]</code> <p>The delta degrees of freedom. Default is <code>0</code>. See <code>numpy.std</code> for more information.</p> <code>0</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/delta_std_preprocessor_fn/#examples","title":"Examples","text":"<p>Here we look at an example where we shift two signals by their std to demonstrate the effect of the delta std preprocessor function.</p>"},{"location":"api/preprocess/functional/delta_std_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<p>First, we define the signals as two normal distributions with different means and standard deviations. Then, we apply the delta std preprocessor function to both signals.</p> <p>A univariate normal distribution with mean \\(\\mu\\) and std \\(\\sigma\\) is defined as:</p> \\[ \\mathcal{N}(\\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}} \\] <pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\n# Number of samples\nn_samples = 100\n# Generate sample data\nx1 = np.random.normal(0, 1, n_samples)\nx2 = np.random.normal(5, 5, n_samples)\nshifted_x1 = PF.delta_std_tf(x1)\nshifted_x2 = PF.delta_std_tf(x2)\n</code></pre>"},{"location":"api/preprocess/functional/delta_std_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<p>Next, we visualize the effect of the transform on the signals.</p> <pre><code>import matplotlib.pyplot as plt\n# Plot original data\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.plot(x1, 'b.', label='x1')\nplt.plot(x2, 'r.', label='x2')\nplt.legend()\nplt.title('Original Data')\n# Plot shifted data\nplt.subplot(1, 2, 2)\nplt.plot(shifted_x1, 'b.', label='x1 shifted')\nplt.plot(shifted_x2, 'r.', label='x2 shifted')\nplt.legend()\nplt.title('Shifted Data')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/delta_var_preprocessor_fn/","title":"delta var","text":""},{"location":"api/preprocess/functional/delta_var_preprocessor_fn/#delta_var_preprocessor","title":"Delta Var Preprocessor","text":"<p>The delta var preprocessor function shifts the input signal by the var of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\sigma^{2}_{x}, \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>delta preprocessor</code> function. For more on how we compute the var of a signal, check out <code>var</code> function.</p> <p>Preprocess the signal <code>x</code> shifting each element of <code>x</code> by the variance of <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to shift by its variance.</p> required <code>ddof</code> <code>Union[int, int_]</code> <p>The delta degrees of freedom. Default is <code>0</code>. See <code>numpy.var</code> for more information.</p> <code>0</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/delta_var_preprocessor_fn/#examples","title":"Examples","text":"<p>Here we look at an example where we shift two signals by their var to demonstrate the effect of the delta var preprocessor function.</p>"},{"location":"api/preprocess/functional/delta_var_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<p>First, we define the signals as two normal distributions with different means and variances. Then, we apply the delta var preprocessor function to both signals.</p> <p>A univariate normal distribution with mean \\(\\mu\\) and var \\(\\sigma\\) is defined as:</p> \\[ \\mathcal{N}(\\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}} \\] <pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\n# Number of samples\nn_samples = 100\n# Generate sample data\nx1 = np.random.normal(0, 1, n_samples)\nx2 = np.random.normal(5, 5, n_samples)\nshifted_x1 = PF.delta_var_tf(x1)\nshifted_x2 = PF.delta_var_tf(x2)\n</code></pre>"},{"location":"api/preprocess/functional/delta_var_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<p>Next, we visualize the effect of the transform on the signals.</p> <pre><code>import matplotlib.pyplot as plt\n# Plot original data\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.plot(x1, '.', color='green', label='x1')\nplt.plot(x2, '.', color='orange', label='x2')\nplt.legend()\nplt.title('Original Data')\n# Plot shifted data\nplt.subplot(1, 2, 2)\nplt.plot(shifted_x1, '.', color='green', label='x1 shifted')\nplt.plot(shifted_x2, '.', color='orange', label='x2 shifted')\nplt.legend()\nplt.title('Shifted Data')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/dft_preprocessor_fn/","title":"1D DFT","text":""},{"location":"api/preprocess/functional/dft_preprocessor_fn/#discrete_fourier_transform_preprocessor","title":"Discrete Fourier Transform Preprocessor","text":"<p>This computes the 1D discrete Fourier transform (DFT) of the input signal. The Fourier transform is efficiently computed using the fast Fourier transform algorithm utilizing symmetries in the computed terms. The algorithm is fastest for 2 powers of \\(N\\) i.e. \\(2^{N}\\). See numpy.fft.fft for more details. The 1D DFT is defined as:</p> \\[ X_k = \\sum_{n=0}^{N-1} x_n e^{-2\\pi i k n / N}, \\quad k = 0, \\ldots, N-1. \\] <p>where \\(N\\) is the number of samples and \\(k\\) is the frequency index.</p>"},{"location":"api/preprocess/functional/dft_preprocessor_fn/#limitations","title":"Limitations","text":"<ul> <li>The input signal must be real-valued.</li> <li>The transform is sensitive to noise and outliers.</li> </ul>"},{"location":"api/preprocess/functional/dft_preprocessor_fn/#autonfeat.preprocess.functional.dft.dft_tf","title":"<code>dft_tf(x, n=None, norm='backward', where=lambda : not np.isnan(x))</code>","text":"<p>Compute the 1D discete Fourier Transform (DFT) using Fast-Fourier Transform (FFT) on the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the DFT of.</p> required <code>n</code> <code>Union[int, int_]</code> <p>The number of points to use for the FFT. If <code>None</code>, the length of <code>x</code> is used. Default is <code>None</code>.</p> <code>None</code> <code>norm</code> <code>str</code> <p>The normalization mode to use. Default is 'backward'. See <code>numpy.fft</code> for more information.         Options include:</p> <pre><code>    'backward': The backward transform is scaled by `1/n`.\n    'ortho': The forward and backward transforms are scaled by `1/sqrt(n)`.\n    'forward': The forward transform is not scaled.\n</code></pre> <code>'backward'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The 1D DFT of <code>x</code>.  It should be noted that the result contains complex numbers. The absolute value of the result can be considered for further processing.</p>"},{"location":"api/preprocess/functional/dft_preprocessor_fn/#examples","title":"Examples","text":"<p>We define as signal as \\(f(t) = 2 \\sin(2 \\pi t) + \\sin(10 \\cdot 2 \\pi t)\\) for \\(t \\in [1, 10]\\) with a sampling rate of 100 samples per second. The signal is then transformed using the DFT preprocessor.</p>"},{"location":"api/preprocess/functional/dft_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\nstart_time = 1  # Start time in seconds\nend_time = 10    # End time in seconds\nsampling_rate = 100  # Number of samples per second\nnum_samples = int((end_time - start_time) * sampling_rate)\n# Signal = 2 x sin(2 x pi x t) + sin(10 x 2 x pi x t)\ntime = np.linspace(start_time, end_time, num_samples)\nsignal = 2 * np.sin(2 * np.pi * time) + np.sin(10 * 2 * np.pi * time)\n# Preprocess and transform signal\ntransformed_signal = PF.dft_tf(signal)\n</code></pre>"},{"location":"api/preprocess/functional/dft_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<p>We then visualize the signal and its Fourier transform. The signal in the frequency domain may be able to identify important features in the signal that were otherwise not visible in the time domain.</p> <pre><code>import matplotlib.pyplot as plt\n# Plot results\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6))\nax1.plot(time, signal)\nax1.set_xlabel(\"Time (s)\")\nax1.set_ylabel(\"f(t)\")\nax2.plot(\nnp.fft.fftfreq(num_samples, 1 / sampling_rate), \nnp.abs(transformed_signal)\n)\nax2.set_xlabel(\"Frequency (Hz)\")\nax2.set_ylabel(\"| FFT(f(x)) |\")\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/lag_preprocessor_fn/","title":"lag","text":""},{"location":"api/preprocess/functional/lag_preprocessor_fn/#lag_preprocessor","title":"Lag Preprocessor","text":"<p>This preprocessor computes the lag transform of the input signal. This is shifts the signal elements by some an integer value to a new index. The lag transform is defined as:</p> \\[ x_{t, \\tau} = x_{t - \\tau} \\] <p>where \\(x_{t, \\tau}\\) is the lag transform of \\(x_t\\) by some integer amount \\(\\tau\\).</p> <p>The lag transform is useful for:</p> <ul> <li>Identifying periodicity in the signal.</li> <li>Identifying trends in the signal.</li> </ul>"},{"location":"api/preprocess/functional/lag_preprocessor_fn/#limitations","title":"Limitations","text":"<ul> <li>When the signal is lagged, the first \\(\\tau\\) elements are set to <code>np.nan</code> values. This is because the lag transform is undefined for these elements. Therefore, when being used the user must ensure that these values are handled appropriately.</li> <li>Only arrays of <code>floats</code> are supported. If passed an array of another type, it will be cast to <code>float</code>. If this fails, the function will raise an exception.</li> </ul> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting the <code>signal</code> by some <code>delta</code> value.</p>"},{"location":"api/preprocess/functional/lag_preprocessor_fn/#autonfeat.preprocess.transform.LagPreprocessor.__call__","title":"<code>__call__(signal, lag, where=lambda : not np.isnan(x))</code>","text":"<p>Roll the <code>signal</code> by a <code>lag</code> where <code>where</code> is <code>True</code>. This pads the shifted signal with <code>NaN</code> values.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to roll.</p> required <code>lag</code> <code>Union[int, float, int_, float_]</code> <p>The lag to apply to the signal.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/functional/lag_preprocessor_fn/#examples","title":"Examples","text":"<p>Consider the following discrete 1D signal:</p> \\[ x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] \\]"},{"location":"api/preprocess/functional/lag_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Define signal\nnum_samples = 10\nsignal = np.arange(1, num_samples + 1)\nlag = 2\n# Preprocess and transform signal\ntransformed_signal = preprocessor(signal, lag=lag)\n</code></pre>"},{"location":"api/preprocess/functional/lag_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<p>We then visualize the signal and the transformed signal. The transformed signal is shifted by some integer amount \\(\\tau = 2\\). For visualization, we convert any <code>np.nan</code> values to <code>0</code>.</p> <pre><code>import matplotlib.pyplot as plt\ntransformed_signal = np.nan_to_num(transformed_signal)\n# Plot results\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\nax.plot(signal, label='Original Signal')\nax.plot(transformed_signal, label='Lag Transformed Signal')\nax.set_xlabel('Time')\nax.set_ylabel('Signal')\nax.set_title('Lag Preprocessor')\nax.legend()\nax.grid()\nplt.show()\n</code></pre> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/functional/power_spectrum_preprocessor_fn/","title":"power spectrum","text":""},{"location":"api/preprocess/functional/power_spectrum_preprocessor_fn/#power_spectrum_preprocessor","title":"Power Spectrum Preprocessor","text":"<p>This preprocessor computes the power spectrum of a given signal, using the 1D Discrete Fourier Transform (DFT). The power spectrum is the squared magnitude of the Fourier transform of the signal. We first compute the DFT with the following:</p> \\[ X_k = \\sum_{n=0}^{N-1} x_n e^{-2\\pi i k n / N}, \\quad k = 0, \\ldots, N-1. \\] <p>where \\(N\\) is the number of samples and \\(k\\) is the frequency index.</p> <p>We can then compute the power spectrum as:</p> \\[ P_k = |X_k|^2, \\quad k = 0, \\ldots, N-1. \\] <p>The power spectrum is useful for identifying important features in the signal that may not be visible in the time domain. </p> <p>The spectral density can be computed as:</p> \\[ S_k = \\frac{2}{f_s N} P_k, \\quad k = 0, \\ldots, N-1. \\] <p>The spectral density is the power spectrum normalized by the number of samples and sampling frequency. The spectral density is useful for comparing signals with different sampling rates and number of samples.</p> <p>where \\(f_s\\) is the sampling frequency.</p>"},{"location":"api/preprocess/functional/power_spectrum_preprocessor_fn/#limitations","title":"Limitations","text":"<ul> <li>The input signal must be real-valued.</li> <li>The transform is sensitive to noise and outliers.</li> </ul> <p>Compute the power spectrum on the values in <code>x</code>. This uses a 1D DFT to compute the power spectrum. See <code>autonfeat.preprocess.functional.dft</code> for more information.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The array to compute the power spectrum of.</p> required <code>nfft</code> <code>Union[int, int_]</code> <p>The number of points to use for the FFT (1D DFT). If <code>None</code>, the length of <code>x</code> is used. Default is <code>None</code>.</p> <code>None</code> <code>normfft</code> <code>str</code> <p>The normalization mode to use when computng the FFT (1D DFT). Default is 'backward'. See <code>autonfeat.preprocess.functional.dft</code> for more information.         Options include:</p> <pre><code>    'backward': The backward transform is scaled by `1/n`.\n    'ortho': The forward and backward transforms are scaled by `1/sqrt(n)`.\n    'forward': The forward transform is not scaled.\n</code></pre> <code>'backward'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>Union[float, float_]</code> <p>The power spectrum of <code>x</code>.</p>"},{"location":"api/preprocess/functional/power_spectrum_preprocessor_fn/#examples","title":"Examples","text":"<p>We define as signal as \\(f(t) = 2 \\sin(2 \\pi t) + \\sin(10 \\cdot 2 \\pi t)\\) for \\(t \\in [1, 5]\\) with a sampling rate of 100 samples per second. We then find the 1D DFT, power spectrum and spectral density of the signal.</p>"},{"location":"api/preprocess/functional/power_spectrum_preprocessor_fn/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat.preprocess.functional as PF\nstart_time = 1  # Start time in seconds\nend_time = 5    # End time in seconds\nsampling_rate = 100  # Number of samples per second\nnum_samples = int((end_time - start_time) * sampling_rate)\n# Signal = 5 x sin(2 x pi x t) + sin(10 x 2 x pi x t)\ntime = np.linspace(start_time, end_time, num_samples)\nfreqs = np.fft.fftfreq(num_samples, 1 / sampling_rate)\nsignal = 5 * np.sin(2 * np.pi * time) + np.sin(10 * 2 * np.pi * time)\n# Preprocess and transform signal\nfreq_spectrum = F.dft_tf(x=signal)\npower_spectrum = F.power_spectrum_tf(x=signal)\nspectral_density = (2 / len(freqs)) * (power_spectrum ** 2)\n</code></pre>"},{"location":"api/preprocess/functional/power_spectrum_preprocessor_fn/#visualize_transform","title":"Visualize Transform","text":"<p>We then visualize the signal, its Fourier transform, the power spectrum and the spectral density. </p> <pre><code>import matplotlib.pyplot as plt\n# Plot results\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 6))\n# Plot signal\nax1.plot(time, signal)\nax1.set_xlabel(\"Time (s)\")\nax1.set_ylabel(\"f(t)\")\nax1.set_title(\"Signal\")\n# Plot frequency spectrum\nax2.plot(freqs, np.abs(freq_spectrum))\nax2.set_xlabel(\"Frequency (Hz)\")\nax2.set_ylabel(\"| FFT(f(x)) |\")\nax2.set_title(\"Frequency Spectrum\")\n# Plot power spectrum\nax3.plot(freqs, power_spectrum)\nax3.set_xlabel(\"Frequency (Hz)\")\nax3.set_ylabel(\"Power\")\nax3.set_title(\"Power Spectrum\")\n# Plot spectral density\nax4.plot(freqs, spectral_density)\nax4.set_xlabel(\"Frequency (Hz)\")\nax4.set_ylabel(\"Spectral Density\")\nax4.set_title(\"Spectral Density\")\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/delta_max_preprocessor/","title":"Delta Max Transform","text":""},{"location":"api/preprocess/transform/delta_max_preprocessor/#delta_max_preprocessor_transform","title":"Delta Max Preprocessor Transform","text":"<p>The Delta Max Preprocessor Transform shifts the input signal by the max of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\max({x}), \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>Delta Transform Preprocessor</code>. For more on how we compute the max of a signal, check out <code>max</code> function.</p> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting the signal down by the maximum value.</p>"},{"location":"api/preprocess/transform/delta_max_preprocessor/#autonfeat.preprocess.transform.DeltaMaxPreprocessor.__call__","title":"<code>__call__(signal, where=lambda : not np.isnan(x), initial=-np.inf)</code>","text":"<p>Compute the difference between the values in <code>signal</code> and <code>max</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the delta with.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <code>initial</code> <code>Union[int, float, int_, float_]</code> <p>The initial value for the maximum. Default is <code>-np.inf</code>.</p> <code>-inf</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/delta_max_preprocessor/#examples","title":"Examples","text":"<p>Consider the following example. We generate a sound wave with a frequencey of 500Hz. The sound wave may contain magnitudes that are not safe for the human ear. We can apply the delta max transform to shift the signal such that it falls within a safe range.</p>"},{"location":"api/preprocess/transform/delta_max_preprocessor/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Create a random signal\ntime = np.linspace(0, 10, 1000)\nfrequency = 500  # Frequency of the signal in Hz\nsound_wave = np.sin(2 * np.pi * frequency * time) + 0.5 * np.sin(2 * np.pi * 2 * frequency * time) + 0.25 * np.sin(2 * np.pi * 3 * frequency * time)\n# Create Preprocessor\npreprocessor = aft.preprocess.DeltaMaxPreprocessor()\n# Shift the sound wave by the peak value to ensure safe listening levels\n# if we define a safe listening level as 0.5\nsafe_level = 0.5\nsafe_sound = preprocessor(sound_wave) + safe_level\n</code></pre>"},{"location":"api/preprocess/transform/delta_max_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<pre><code>import matplotlib.pyplot as plt\n# Plot the original signal and the shifted signal\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(time, sound_wave, label='Original Signal')\nax.plot(time, safe_sound, label='Shifted Signal')\nax.axhline(y=safe_level, color='red', linestyle='--', linewidth=2)\nax.annotate('Safe Listening Level', xy=(0, safe_level), xytext=(0.5, safe_level + 0.1), arrowprops=dict(facecolor='black', shrink=0.05))\nax.set_xlabel('Time (s)')\nax.set_ylabel('Amplitude')\nax.set_title('Sound Wave')\nax.legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/delta_mean_preprocessor/","title":"Delta Mean Transform","text":""},{"location":"api/preprocess/transform/delta_mean_preprocessor/#delta_mean_preprocessor_transform","title":"Delta Mean Preprocessor Transform","text":"<p>The Delta Mean Preprocessor Transform shifts the input signal by the mean of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\mu_{x}, \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>Delta Transform Preprocessor</code>. For more on how we compute the mean of a signal, check out <code>mean</code> function.</p> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by computing a delta (using <code>mean</code>) with elements of a <code>signal</code> and shifting the <code>signal</code> by this delta.</p>"},{"location":"api/preprocess/transform/delta_mean_preprocessor/#autonfeat.preprocess.transform.DeltaMeanPreprocessor.__call__","title":"<code>__call__(signal, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the difference between the values in <code>signal</code> and <code>mean</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the delta with.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/delta_mean_preprocessor/#examples","title":"Examples","text":""},{"location":"api/preprocess/transform/delta_mean_preprocessor/#transform_signal","title":"Transform Signal","text":"<p>We sample from a normal distribution with mean \\(\\mu = 10\\) and standard deviation \\(\\sigma = 1\\). We then apply the delta mean transform to shift the distribution to be centered at zero.</p> <p>A 1D normal distribution centered at \\(\\mu\\) with standard deviation \\(\\sigma\\) is defined as:</p> \\[ f(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}} \\] <pre><code>import numpy as np\nimport autonfeat as aft\n# Parameters for the normal distribution\nmu = 50      # Mean\nsigma = 1   # Standard deviation\nn_samples = 10000\n# Generate random samples from the normal distribution\nsamples = np.random.normal(mu, sigma, n_samples)\n# Create Preprocessor\npreprocessor = aft.preprocess.DeltaMeanPreprocessor()\n# Preprocess signal\ntransformed_samples = preprocessor(samples)\n</code></pre>"},{"location":"api/preprocess/transform/delta_mean_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<p>We can observe a shift in the distribution of the signal after applying the delta mean transform. The distribution is shifted to be centered at zero.</p> <pre><code>import matplotlib.pyplot as plt\n# Compute the range and pdf for plotting\nx = np.linspace(mu - 4 * sigma, mu + 4 * sigma, n_samples)\npdf = 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-(x - mu)**2 / (2 * sigma**2))\n# Compute the expected range and pdf for plotting\nx_shifted = x - mu\ntransformed_pdf = 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-(x_shifted)**2 / (2 * sigma**2))\n# Plot one below the other\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\nax1.hist(samples, bins=50, density=True, alpha=0.7, color='grey')\nax1.plot(x, pdf, color='blue', linewidth=2)\nax1.axvline(x=mu, color='red', linestyle='--', linewidth=2)\nax1.set_xlabel('x')\nax1.set_ylabel('Probability Density')\nax1.set_title('Normal Distribution Centered at {:.2f}'.format(mu))\nax2.hist(transformed_samples, bins=50, density=True, alpha=0.7, color='grey')\nax2.plot(x_shifted, transformed_pdf, color='blue', linewidth=2)\nax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\nax2.set_xlabel('x')\nax2.set_ylabel('Probability Density')\nax2.set_title('Normal Distribution Centered at {:.2f}'.format(0))\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/delta_median_preprocessor/","title":"Delta Median Transform","text":""},{"location":"api/preprocess/transform/delta_median_preprocessor/#delta_median_preprocessor_transform","title":"Delta Median Preprocessor Transform","text":"<p>The Delta Median Preprocessor Transform shifts the input signal by the median of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - median({x}), \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>Delta Transform Preprocessor</code>. For more on how we compute the median of a signal, check out <code>median</code> function.</p> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting the signal up by the median value.</p>"},{"location":"api/preprocess/transform/delta_median_preprocessor/#autonfeat.preprocess.transform.DeltaMedianPreprocessor.__call__","title":"<code>__call__(signal, method='linear', where=lambda : not np.isnan(x))</code>","text":"<p>Compute the difference between the values in <code>signal</code> and <code>median</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the delta with.</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantile. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/delta_median_preprocessor/#examples","title":"Examples","text":"<p>Signal equilization is a common problem in signal processing. The Delta Median Preprocessor Transform can be used to equilize signals by shifting them by their median. This can be useful for removing the effect of a constant bias in the signal. This is often done in sound engineering when equilizing the sound of different instruments. In the example below, we generate three signals, a guitar signal, a piano signal, and a drums signal. We then apply the Delta Median Preprocessor Transform to each signal.</p>"},{"location":"api/preprocess/transform/delta_median_preprocessor/#transform_signal","title":"Transform Signal","text":"<p>We first generate the signals. Then we perform the equilization by applying the transform to each signal.</p> <pre><code>import numpy as np\nimport autonfeat as aft\n# Generating example signals for each instrument\nnum_samples = 100\ntime = np.linspace(0, 1, num_samples)\nguitar_signal = np.sin(2 * np.pi * 10 * time)  # Guitar signal (higher frequency sine wave)\npiano_signal = np.cos(2 * np.pi * 2 * time)  # Piano signal (cosine wave)\ndrums_signal = np.random.normal(2, 0.5, num_samples)  # Drums signal (random noise with higher mean)\n# Defining the transform\npreprocessor = aft.preprocess.DeltaMedianPreprocessor()\n# Applying the transform to each signal\nguitar_eq = preprocessor(guitar_signal)\npiano_eq = preprocessor(piano_signal)\ndrums_eq = preprocessor(drums_signal)\n</code></pre>"},{"location":"api/preprocess/transform/delta_median_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<p>We can visualize the effect of the transform by plotting the original signals and the shifted signals on the same plot. We can see that the median of each signal is shifted to zero.</p> <pre><code>import matplotlib.pyplot as plt\n# Set up custom line styles\nline_styles = ['-', '--', '-.']\n# Set up custom color palette\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n# Plotting all original signals on one subplot\nplt.figure(figsize=(10, 10))\nplt.subplot(2, 1, 1)\nfor i, signal in enumerate([guitar_signal, piano_signal, drums_signal]):\nplt.plot(time, signal, color=colors[i], linestyle=line_styles[i])\nplt.title('Original Signals')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.legend(['Guitar', 'Piano', 'Drums'])\nplt.grid(True)\n# Plotting all shifted signals on another subplot\nplt.subplot(2, 1, 2)\nfor i, signal in enumerate([guitar_eq, piano_eq, drums_eq]):\nplt.plot(time, signal, color=colors[i], linestyle=line_styles[i])\nplt.title('Shifted Signals')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.legend(['Guitar', 'Piano', 'Drums'])\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <p>As seen in the figure, the drums signal which had a higher mean than the other signals is shifted down by a larger amount than the other signals. In doing so, we have equilized the signals.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/delta_min_preprocessor/","title":"Delta Min Transform","text":""},{"location":"api/preprocess/transform/delta_min_preprocessor/#delta_min_preprocessor_transform","title":"Delta Min Preprocessor Transform","text":"<p>The Delta Min Preprocessor Transform shifts the input signal by the max of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\min({x}), \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>Delta Transform Preprocessor</code>. For more on how we compute the min of a signal, check out <code>min</code> function.</p> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting the signal up by the minimum value.</p>"},{"location":"api/preprocess/transform/delta_min_preprocessor/#autonfeat.preprocess.transform.DeltaMinPreprocessor.__call__","title":"<code>__call__(signal, where=lambda : not np.isnan(x), initial=np.inf)</code>","text":"<p>Compute the difference between the values in <code>signal</code> and <code>min</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the delta with.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <code>initial</code> <code>Union[int, float, int_, float_]</code> <p>The initial value for the minimum. Default is <code>-np.inf</code>.</p> <code>inf</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/delta_min_preprocessor/#examples","title":"Examples","text":""},{"location":"api/preprocess/transform/delta_min_preprocessor/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Create a random signal\ntime = np.linspace(0, 10, 1000)\nfrequency = 500  # Frequency of the signal in Hz\nsignal = np.sin(np.exp(np.sin(2 * np.pi * frequency * time)))\n# Create Preprocessor\npreprocessor = aft.preprocess.DeltaMinPreprocessor()\n# Shift the signal by the minimum value\nshifted_signal = preprocessor(signal)\n</code></pre>"},{"location":"api/preprocess/transform/delta_min_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<pre><code>import matplotlib.pyplot as plt\n# Plot the original signal and the shifted signal\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(time, signal, label='Original Signal')\nax.plot(time, shifted_signal, label='Shifted Signal')\nax.axhline(y=0, color='red', linestyle='--', linewidth=2)\nax.set_xlabel('Time (s)')\nax.set_ylabel('Amplitude')\nax.set_title('Signal')\nax.legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/delta_preprocessor/","title":"Delta Transform","text":""},{"location":"api/preprocess/transform/delta_preprocessor/#delta_preprocessor_transform","title":"Delta Preprocessor Transform","text":"<p>The Delta Preprocessor Transform shifts the input signal by a fixed amount. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\delta, \\quad \\forall i \\in \\{1, \\dots, N\\}, \\quad \\delta \\in \\mathbb{R} \\] <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting the <code>signal</code> by some <code>delta</code> value.</p>"},{"location":"api/preprocess/transform/delta_preprocessor/#autonfeat.preprocess.transform.DeltaPreprocessor.__call__","title":"<code>__call__(signal, delta, where=lambda : not np.isnan(x))</code>","text":"<p>Shift the <code>signal</code> by a <code>delta</code> where <code>where</code> is <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to shift.</p> required <code>delta</code> <code>Union[int, float, int_, float_]</code> <p>The value to shift by.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/delta_preprocessor/#examples","title":"Examples","text":"<p>Consider a system that feeds in to a half-wave rectifier. Half-wave rectifiers are used to remove the negative portion of a signal and are use in many applications such as power supplies and AM radios. The half-wave rectifier is defined as:</p> \\[ y_{i} = \\max(x_{i}, 0) =  \\begin{cases} x_{i}, &amp; \\text{if } x_{i} \\geq 0 \\\\ 0, &amp; \\text{if } x_{i} &lt; 0 \\end{cases} , \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>where \\(x_{i}\\) represents an element of the input signal, \\(y_{i}\\) represents an element of the output signal, and \\(N\\) is the number of elements in the signal. </p> <p>Suppose we want to apply the half-wave rectifer to just the AC part of a signal containing both AC and DC components, we can use the Delta Preprocessor Transform to eliminate the DC component.</p>"},{"location":"api/preprocess/transform/delta_preprocessor/#define_signal_hwr_system_and_preprocessor","title":"Define Signal, HWR System, and Preprocessor","text":"<p>Define a signal with the following parameters:</p> \\[ signal_{i} = DC_{offset} + AC_{amp} \\cdot \\sin(2 \\pi \\cdot freq \\cdot time_{i}) \\] <p>\\(DC_{offset} = 5\\) V</p> <p>\\(AC_{amp} = 2\\) V</p> <p>\\(freq = 500\\) Hz</p> <p>\\(N = 1000\\) samples</p> <p>\\(T = 10\\) s</p> <pre><code>import numpy as np\nimport autonfeat as aft\n# Define signal\ntime = np.linspace(0, 10, 1000) # secs\nfreq = 500                      # Hz\ndc_offset = 5                   # V\nac_amp = 2                      # V\nsignal = dc_offset + ac_amp * np.sin(2 * np.pi * freq * time)\n# Define half-wave rectifier\nhalf_wave_rectifier = lambda x_i: np.maximum(x_i, 0)\n# Define delta transform preprocessor\npreprocessor = aft.preprocess.DeltaPreprocessor()\n</code></pre>"},{"location":"api/preprocess/transform/delta_preprocessor/#transform_signal","title":"Transform Signal","text":"<p>Transform the signal by the delta transform preprocessor and apply the half-wave rectifier. This will remove the DC component by setting \\(\\delta = DC_{offset} = 5\\) V.</p> <pre><code>delta = dc_offset # Amount to shift by\n# Preprocess signal\nsignal_transformed = preprocessor(signal, delta=delta)\n# Apply half-wave rectifier\nsystem_output = half_wave_rectifier(signal_transformed)\n</code></pre>"},{"location":"api/preprocess/transform/delta_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<p>Visualize the signal, the transformed signal, and the output of the half-wave rectifier with and without the delta transform preprocessor.</p> <pre><code>import matplotlib.pyplot as plt\n# Plot results\nfig, (ax1, ax2) = plt.subplots(2, 2, figsize=(10, 6))\n# Plot signal and output of half-wave rectifier (before delta transform)\nax1[0].plot(time, signal, label='Signal')\nax1[0].set_xlabel('Time (s)')\nax1[0].set_ylabel('Voltage (V)')\nax1[0].set_title('Original Signal')\nax1[0].grid(True)\nax1[0].legend()\nax1[1].plot(time, half_wave_rectifier(signal), color='orange', label='Output')\nax1[1].set_xlabel('Time (s)')\nax1[1].set_ylabel('Voltage (V)')\nax1[1].set_title('Output of Half-Wave Rectifier (Before Delta Transform)')\nax1[1].grid(True)\nax1[1].legend()\n# Plot signal and output of half-wave rectifier (after delta transform)\nax2[0].plot(time, signal_transformed, label='Signal')\nax2[0].set_xlabel('Time (s)')\nax2[0].set_ylabel('Voltage (V)')\nax2[0].set_title('Signal After Delta Transform')\nax2[0].grid(True)\nax2[0].legend()\nax2[1].plot(time, system_output, color='orange', label='Output')\nax2[1].set_xlabel('Time (s)')\nax2[1].set_ylabel('Voltage (V)')\nax2[1].set_title('Output of Half-Wave Rectifier (After Delta Transform)')\nax2[1].grid(True)\nax2[1].legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p>We can observe how with the help of the Delta Preprocessor Transform, shifting the signal by the DC offset of the signal eliminates the DC component of the signal and allows the half-wave rectifier to only act on the AC component of the signal.</p> <p></p>"},{"location":"api/preprocess/transform/delta_preprocessor/#fun_fact","title":"Fun Fact","text":"<p>Half-wave rectifiers are equivalent to a rectified linear unit i.e. the \\(ReLU\\) activation function used in neural networks.</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/delta_quantile_preprocessor/","title":"Delta Quantile Transform","text":""},{"location":"api/preprocess/transform/delta_quantile_preprocessor/#delta_quantile_preprocessor_transform","title":"Delta Quantile Preprocessor Transform","text":"<p>The Delta Quantile Preprocessor Transform shifts the input signal by the quantile of the signal. This is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\text{quantile}(x), \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>where \\(x_{i}\\) represents an element of the input signal, \\(x_{shifted_{i}}\\) represents an element of the output signal, and \\(N\\) is the number of elements in the signal.</p> <p>For shifting signals by a custom \\(\\delta\\), see the <code>Delta Transform Preprocessor</code>. For more on how we compute the quantile of a signal, check out <code>quantile</code> function.</p> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting each element in the signal by the quantile of the signal.</p>"},{"location":"api/preprocess/transform/delta_quantile_preprocessor/#autonfeat.preprocess.transform.DeltaQuantilePreprocessor.__call__","title":"<code>__call__(signal, q, method='linear', where=lambda : not np.isnan(x))</code>","text":"<p>Compute the quantile of the signal and shift the signal by this quantile.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the delta with.</p> required <code>q</code> <code>Union[float, float_]</code> <p>The quantile to compute. Must be between 0 and 1.</p> required <code>method</code> <code>str</code> <p>The method to use when computing the quantile. Default is 'linear'. See <code>numpy.quantile</code> for more information.</p> <code>'linear'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/delta_quantile_preprocessor/#examples","title":"Examples","text":""},{"location":"api/preprocess/transform/delta_quantile_preprocessor/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Generate data\nn_samples = 1000\nx = np.random.normal(-5, 5, n_samples)\n# Create a preprocessor\npreprocessor = aft.preprocess.DeltaQuantilePreprocessor()\nq_tile = 0.25 # 25th quantile\n# Preprocess data\nx_shifted = preprocessor(x, q=q_tile)\n</code></pre>"},{"location":"api/preprocess/transform/delta_quantile_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<pre><code>import matplotlib.pyplot as plt\n# Plot normal and shifted data\noriginal_quantile = aft.functional.quantile_tf(x, q_tile)\nshifted_quantile = aft.functional.quantile_tf(x_shifted, q_tile)\nplt.figure(figsize=(8, 6))\nplt.plot(x, '.', color='blue', label='Origianl Data')\nplt.axhline(original_quantile, color='red', linestyle='--', linewidth=3, label=f'Original Data 25th quantile = {original_quantile:.2f}')\nplt.plot(x_shifted, '.', color='orange', label='Shifted Data')\nplt.axhline(shifted_quantile, color='green', linestyle='--', linewidth=3, label=f'Shifted Data 25th quantile = {shifted_quantile:.2f}')\nplt.legend()\nplt.title('Delta Quantile Preprocessing Transform')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/delta_std_preprocessor/","title":"Delta Std Transform","text":""},{"location":"api/preprocess/transform/delta_std_preprocessor/#delta_std_preprocessor_transform","title":"Delta Std Preprocessor Transform","text":"<p>The Delta Std Preprocessor Transform shifts the input signal by the std of the signal. This is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\sigma_{x}, \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>Delta Transform Preprocessor</code>. For more on how we compute the std of a signal, check out <code>std</code> function.</p> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting each element in the signal by the standard deviation of the signal.</p>"},{"location":"api/preprocess/transform/delta_std_preprocessor/#autonfeat.preprocess.transform.DeltaStdPreprocessor.__call__","title":"<code>__call__(signal, ddof=0, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the standard deviation of the signal and shift the signal by this standard deviation.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the delta with.</p> required <code>ddof</code> <code>Union[int, int_]</code> <p>The delta degrees of freedom. Default is <code>0</code>. See <code>numpy.std</code> for more information.</p> <code>0</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/delta_std_preprocessor/#examples","title":"Examples","text":"<p>Here we look at an example where we shift two signals by their std to demonstrate the effect of the Delta Std Preprocessor Transform.</p>"},{"location":"api/preprocess/transform/delta_std_preprocessor/#transform_signal","title":"Transform Signal","text":"<p>First, we define the signals as two normal distributions with different means and standard deviations. Then, we apply the Delta Std Preprocessor Transform to both signals.</p> <p>A univariate normal distribution with mean \\(\\mu\\) and std \\(\\sigma\\) is defined as:</p> \\[ \\mathcal{N}(\\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}} \\] <pre><code>import numpy as np\nimport autonfeat as aft\n# Number of samples\nn_samples = 100\n# Generate sample data\nx1 = np.random.normal(0, 1, n_samples)\nx2 = np.random.normal(5, 5, n_samples)\n# Define preprocessor\npreprocessor = aft.preprocess.DeltaStdPreprocessor()\nshifted_x1 = preprocessor(x1)\nshifted_x2 = preprocessor(x2)\n</code></pre>"},{"location":"api/preprocess/transform/delta_std_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<p>Next, we visualize the effect of the transform on the signals.</p> <pre><code>import matplotlib.pyplot as plt\n# Plot original data\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.plot(x1, 'b.', label='x1')\nplt.plot(x2, 'r.', label='x2')\nplt.legend()\nplt.title('Original Data')\n# Plot shifted data\nplt.subplot(1, 2, 2)\nplt.plot(shifted_x1, 'b.', label='x1 shifted')\nplt.plot(shifted_x2, 'r.', label='x2 shifted')\nplt.legend()\nplt.title('Shifted Data')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/delta_var_preprocessor/","title":"Delta Var Transform","text":""},{"location":"api/preprocess/transform/delta_var_preprocessor/#delta_var_preprocessor_transform","title":"Delta Var Preprocessor Transform","text":"<p>The Delta Var Preprocessor Transform shifts the input signal by the var of the signal. The is defined as:</p> \\[ x_{shifted_{i}} = x_{i} - \\sigma^{2}_{x}, \\quad \\forall i \\in \\{1, \\dots, N\\} \\] <p>For shifting signals by a custom \\(\\delta\\), see the <code>Delta Transform Preprocessor</code>. For more on how we compute the var of a signal, check out <code>var</code> function.</p> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting each element in the signal by the variance of the signal.</p>"},{"location":"api/preprocess/transform/delta_var_preprocessor/#autonfeat.preprocess.transform.DeltaVarPreprocessor.__call__","title":"<code>__call__(signal, ddof=0, where=lambda : not np.isnan(x))</code>","text":"<p>Compute the variance of the signal and shift the signal by this variance.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the delta with.</p> required <code>ddof</code> <code>Union[int, int_]</code> <p>The delta degrees of freedom. Default is <code>0</code>. See <code>numpy.var</code> for more information.</p> <code>0</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/delta_var_preprocessor/#examples","title":"Examples","text":"<p>Here we look at an example where we shift two signals by their var to demonstrate the effect of the Delta Var Preprocessor Transform.</p>"},{"location":"api/preprocess/transform/delta_var_preprocessor/#transform_signal","title":"Transform Signal","text":"<p>First, we define the signals as two normal distributions with different means and variances. Then, we apply the Delta Var Preprocessor Transform to both signals.</p> <p>A univariate normal distribution with mean \\(\\mu\\) and var \\(\\sigma\\) is defined as:</p> \\[ \\mathcal{N}(\\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^{2}}{2 \\sigma^{2}}} \\] <pre><code>import numpy as np\nimport autonfeat as aft\n# Number of samples\nn_samples = 100\n# Generate sample data\nx1 = np.random.normal(0, 1, n_samples)\nx2 = np.random.normal(5, 5, n_samples)\n# Define preprocessor\npreprocessor = aft.preprocess.DeltaVarPreprocessor()\nshifted_x1 = preprocessor(x1)\nshifted_x2 = preprocessor(x2)\n</code></pre>"},{"location":"api/preprocess/transform/delta_var_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<p>Next, we visualize the effect of the transform on the signals.</p> <pre><code>import matplotlib.pyplot as plt\n# Plot original data\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.plot(x1, '.', color='green', label='x1')\nplt.plot(x2, '.', color='orange', label='x2')\nplt.legend()\nplt.title('Original Data')\n# Plot shifted data\nplt.subplot(1, 2, 2)\nplt.plot(shifted_x1, '.', color='green', label='x1 shifted')\nplt.plot(shifted_x2, '.', color='orange', label='x2 shifted')\nplt.legend()\nplt.title('Shifted Data')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>This can be seen in the figure below.</p> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/dft_preprocessor/","title":"1D DFT Transform","text":""},{"location":"api/preprocess/transform/dft_preprocessor/#discrete_fourier_transform_preprocessor","title":"Discrete Fourier Transform Preprocessor","text":"<p>This computes the 1D discrete Fourier transform (DFT) of the input signal. The Fourier transform is efficiently computed using the fast Fourier transform algorithm utilizing symmetries in the computed terms. The algorithm is fastest for 2 powers of \\(N\\) i.e. \\(2^{N}\\). See numpy.fft.fft for more details. The 1D DFT is defined as:</p> \\[ X_k = \\sum_{n=0}^{N-1} x_n e^{-2\\pi i k n / N}, \\quad k = 0, \\ldots, N-1. \\] <p>where \\(N\\) is the number of samples and \\(k\\) is the frequency index.</p>"},{"location":"api/preprocess/transform/dft_preprocessor/#limitations","title":"Limitations","text":"<ul> <li>The input signal must be real-valued.</li> <li>The transform is sensitive to noise and outliers.</li> </ul> <p>             Bases: <code>Preprocess</code></p> <p>1D Discete Fourier Transform (DFT) using Fast-Fourier Transform (FFT).</p>"},{"location":"api/preprocess/transform/dft_preprocessor/#autonfeat.preprocess.transform.DFTPreprocessor.__call__","title":"<code>__call__(signal, n=None, norm='backward', where=lambda : not np.isnan(x))</code>","text":"<p>Compute the 1D Discete Fourier Transform (DFT) using Fast-Fourier Transform (FFT) on the values in <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the DFT of.</p> required <code>n</code> <code>Union[int, int_]</code> <p>The number of points to use for the FFT. If <code>None</code>, the length of <code>x</code> is used. Default is <code>None</code>.</p> <code>None</code> <code>norm</code> <code>str</code> <p>The normalization mode to use. Default is 'backward'. See <code>numpy.fft</code> for more information.     Options include:</p> <pre><code>'backward': The backward transform is scaled by `1/n`.\n'ortho': The forward and backward transforms are scaled by `1/sqrt(n)`.\n'forward': The forward transform is not scaled.\n</code></pre> <code>'backward'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The 1D DFT of <code>x</code>. It should be noted that the result contains complex numbers. The absolute value of the result can be considered for further processing.</p>"},{"location":"api/preprocess/transform/dft_preprocessor/#examples","title":"Examples","text":"<p>We define as signal as \\(f(t) = 2 \\sin(2 \\pi t) + \\sin(10 \\cdot 2 \\pi t)\\) for \\(t \\in [1, 10]\\) with a sampling rate of 100 samples per second. The signal is then transformed using the DFT preprocessor.</p>"},{"location":"api/preprocess/transform/dft_preprocessor/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat as aft\nstart_time = 1  # Start time in seconds\nend_time = 10    # End time in seconds\nsampling_rate = 100  # Number of samples per second\nnum_samples = int((end_time - start_time) * sampling_rate)\n# Signal = 2 x sin(2 x pi x t) + sin(10 x 2 x pi x t)\ntime = np.linspace(start_time, end_time, num_samples)\nsignal = 2 * np.sin(2 * np.pi * time) + np.sin(10 * 2 * np.pi * time)\n# Create Preprocessor\npreprocessor = aft.preprocess.DFTPreprocessor()\n# Preprocess and transform signal\ntransformed_signal = preprocessor(signal)\n</code></pre>"},{"location":"api/preprocess/transform/dft_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<p>We then visualize the signal and its Fourier transform. The signal in the frequency domain may be able to identify important features in the signal that were otherwise not visible in the time domain.</p> <pre><code>import matplotlib.pyplot as plt\n# Plot results\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6))\nax1.plot(time, signal)\nax1.set_xlabel(\"Time (s)\")\nax1.set_ylabel(\"f(t)\")\nax2.plot(\nnp.fft.fftfreq(num_samples, 1 / sampling_rate), \nnp.abs(transformed_signal)\n)\nax2.set_xlabel(\"Frequency (Hz)\")\nax2.set_ylabel(\"| FFT(f(x)) |\")\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/lag_preprocessor/","title":"Lag Transform","text":""},{"location":"api/preprocess/transform/lag_preprocessor/#lag_transform_preprocessor","title":"Lag Transform Preprocessor","text":"<p>This preprocessor computes the lag transform of the input signal. This is shifts the signal elements by some an integer value to a new index. The lag transform is defined as:</p> \\[ x_{t, \\tau} = x_{t - \\tau} \\] <p>where \\(x_{t, \\tau}\\) is the lag transform of \\(x_t\\) by some integer amount \\(\\tau\\).</p> <p>The lag transform is useful for:</p> <ul> <li>Identifying periodicity in the signal.</li> <li>Identifying trends in the signal.</li> </ul>"},{"location":"api/preprocess/transform/lag_preprocessor/#limitations","title":"Limitations","text":"<ul> <li>When the signal is lagged, the first \\(\\tau\\) elements are set to <code>np.nan</code> values. This is because the lag transform is undefined for these elements. Therefore, when being used the user must ensure that these values are handled appropriately.</li> <li>Only arrays of <code>floats</code> are supported. If passed an array of another type, it will be cast to <code>float</code>. If this fails, the function will raise an exception.</li> </ul> <p>             Bases: <code>Preprocess</code></p> <p>Preprocess the signal by shifting the <code>signal</code> by some <code>delta</code> value.</p>"},{"location":"api/preprocess/transform/lag_preprocessor/#autonfeat.preprocess.transform.LagPreprocessor.__call__","title":"<code>__call__(signal, lag, where=lambda : not np.isnan(x))</code>","text":"<p>Roll the <code>signal</code> by a <code>lag</code> where <code>where</code> is <code>True</code>. This pads the shifted signal with <code>NaN</code> values.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to roll.</p> required <code>lag</code> <code>Union[int, float, int_, float_]</code> <p>The lag to apply to the signal.</p> required <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The shifted signal.</p>"},{"location":"api/preprocess/transform/lag_preprocessor/#examples","title":"Examples","text":"<p>Consider the following discrete 1D signal:</p> \\[ x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] \\]"},{"location":"api/preprocess/transform/lag_preprocessor/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nimport autonfeat as aft\n# Define signal\nnum_samples = 10\nsignal = np.arange(1, num_samples + 1)\nlag = 2\n# Create Preprocessor\npreprocessor = aft.preprocess.LagPreprocessor()\n# Preprocess and transform signal\ntransformed_signal = preprocessor(signal, lag=lag)\n</code></pre>"},{"location":"api/preprocess/transform/lag_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<p>We then visualize the signal and the transformed signal. The transformed signal is shifted by some integer amount \\(\\tau = 2\\). For visualization, we convert any <code>np.nan</code> values to <code>0</code>.</p> <pre><code>import matplotlib.pyplot as plt\ntransformed_signal = np.nan_to_num(transformed_signal)\n# Plot results\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\nax.plot(signal, label='Original Signal')\nax.plot(transformed_signal, label='Lag Transformed Signal')\nax.set_xlabel('Time')\nax.set_ylabel('Signal')\nax.set_title('Lag Preprocessor')\nax.legend()\nax.grid()\nplt.show()\n</code></pre> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/preprocess/transform/power_spectrum_preprocessor/","title":"Power Spectrum Transform","text":""},{"location":"api/preprocess/transform/power_spectrum_preprocessor/#power_spectrum_transform_preprocessor","title":"Power Spectrum Transform Preprocessor","text":"<p>This preprocessor computes the power spectrum of a given signal, using the 1D Discrete Fourier Transform (DFT). The power spectrum is the squared magnitude of the Fourier transform of the signal. We first compute the DFT with the following:</p> \\[ X_k = \\sum_{n=0}^{N-1} x_n e^{-2\\pi i k n / N}, \\quad k = 0, \\ldots, N-1. \\] <p>where \\(N\\) is the number of samples and \\(k\\) is the frequency index.</p> <p>We can then compute the power spectrum as:</p> \\[ P_k = |X_k|^2, \\quad k = 0, \\ldots, N-1. \\] <p>The power spectrum is useful for identifying important features in the signal that may not be visible in the time domain. </p> <p>The spectral density can be computed as:</p> \\[ S_k = \\frac{2}{f_s N} P_k, \\quad k = 0, \\ldots, N-1. \\] <p>The spectral density is the power spectrum normalized by the number of samples and sampling frequency. The spectral density is useful for comparing signals with different sampling rates and number of samples.</p> <p>where \\(f_s\\) is the sampling frequency.</p>"},{"location":"api/preprocess/transform/power_spectrum_preprocessor/#limitations","title":"Limitations","text":"<ul> <li>The input signal must be real-valued.</li> <li>The transform is sensitive to noise and outliers.</li> </ul> <p>             Bases: <code>Preprocess</code></p> <p>Power Spectrum using a 1D DFT.</p>"},{"location":"api/preprocess/transform/power_spectrum_preprocessor/#autonfeat.preprocess.transform.PowerSpectrumPreprocessor.__call__","title":"<code>__call__(signal, nfft=None, normfft='backward', where=lambda : not np.isnan(x))</code>","text":"<p>Compute the power spectrum on the values in <code>x</code>. This uses a 1D DFT to compute the power spectrum. See <code>autonfeat.preprocess.functional.dft</code> for more information.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The array to compute the power spectrum of.</p> required <code>nfft</code> <code>Union[int, int_]</code> <p>The number of points to use for the FFT (1D DFT). If <code>None</code>, the length of <code>x</code> is used. Default is <code>None</code>.</p> <code>None</code> <code>normfft</code> <code>str</code> <p>The normalization mode to use when computng the FFT (1D DFT). Default is 'backward'. See <code>autonfeat.preprocess.functional.dft</code> for more information.     Options include:</p> <pre><code>'backward': The backward transform is scaled by `1/n`.\n'ortho': The forward and backward transforms are scaled by `1/sqrt(n)`.\n'forward': The forward transform is not scaled.\n</code></pre> <code>'backward'</code> <code>where</code> <code>Callable[[Union[int, float, int_, float_]], Union[bool, bool_]]</code> <p>A function that takes a value and returns <code>True</code> or <code>False</code>. Default is <code>lambda x: not np.isnan(x)</code> i.e. a measurement is valid if it is not a <code>NaN</code> value.</p> <code>lambda : not numpy.isnan(x)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The power spectrum of <code>x</code>.</p>"},{"location":"api/preprocess/transform/power_spectrum_preprocessor/#examples","title":"Examples","text":"<p>We define as signal as \\(f(t) = 2 \\sin(2 \\pi t) + \\sin(10 \\cdot 2 \\pi t)\\) for \\(t \\in [1, 5]\\) with a sampling rate of 100 samples per second. We then find the 1D DFT, power spectrum and spectral density of the signal.</p>"},{"location":"api/preprocess/transform/power_spectrum_preprocessor/#transform_signal","title":"Transform Signal","text":"<pre><code>import numpy as np\nfrom autonfeat.preprocess import DFTPreprocessor, PowerSpectrumPreprocessor\nstart_time = 1  # Start time in seconds\nend_time = 5    # End time in seconds\nsampling_rate = 100  # Number of samples per second\nnum_samples = int((end_time - start_time) * sampling_rate)\n# Signal = 5 x sin(2 x pi x t) + sin(10 x 2 x pi x t)\ntime = np.linspace(start_time, end_time, num_samples)\nfreqs = np.fft.fftfreq(num_samples, 1 / sampling_rate)\nsignal = 5 * np.sin(2 * np.pi * time) + np.sin(10 * 2 * np.pi * time)\n# Preprocess and transform signal\ndft_preprocessor = DFTPreprocessor()\npower_spectrum_preprocessor = PowerSpectrumPreprocessor()\nfreq_spectrum = dft_preprocessor(signal=signal)\npower_spectrum = power_spectrum_preprocessor(signal=signal)\nspectral_density = (2 / len(freqs)) * (power_spectrum ** 2)\n</code></pre>"},{"location":"api/preprocess/transform/power_spectrum_preprocessor/#visualize_transform","title":"Visualize Transform","text":"<p>We then visualize the signal, its Fourier transform, the power spectrum and the spectral density. </p> <pre><code>import matplotlib.pyplot as plt\n# Plot results\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 6))\n# Plot signal\nax1.plot(time, signal)\nax1.set_xlabel(\"Time (s)\")\nax1.set_ylabel(\"f(t)\")\nax1.set_title(\"Signal\")\n# Plot frequency spectrum\nax2.plot(freqs, np.abs(freq_spectrum))\nax2.set_xlabel(\"Frequency (Hz)\")\nax2.set_ylabel(\"| FFT(f(x)) |\")\nax2.set_title(\"Frequency Spectrum\")\n# Plot power spectrum\nax3.plot(freqs, power_spectrum)\nax3.set_xlabel(\"Frequency (Hz)\")\nax3.set_ylabel(\"Power\")\nax3.set_title(\"Power Spectrum\")\n# Plot spectral density\nax4.plot(freqs, spectral_density)\nax4.set_xlabel(\"Frequency (Hz)\")\nax4.set_ylabel(\"Spectral Density\")\nax4.set_title(\"Spectral Density\")\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"api/utils/utils/","title":"Utils","text":""},{"location":"api/utils/utils/#utility_functions","title":"Utility Functions","text":""},{"location":"api/utils/utils/#examples","title":"Examples","text":"<p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"community/contributing/","title":"Contributing","text":""},{"location":"community/contributing/#contributing","title":"Contributing","text":"<p>We'd love to hear from you! Feel free to open an issue or a PR if you have any suggestions or find any bugs.</p> <p>When contributing, please add tests to the <code>tests</code> directory. Additionally, we follow <code>flake8</code> as a linter and <code>pytest</code> for testing. Please lint your code before submitting a pull request to maintain design consistency. For documentation, please write docstrings following the Google style guide. We use a variant of this style guide for docstrings as shown below:</p> <pre><code>def mean_tf(x: np.ndarray, where: Callable[[Union[int, float, np.int_, np.float_]], Union[bool, np.bool_]] = lambda x: not np.isnan(x)) -&gt; Union[float, np.float_]:\n\"\"\"\n    Compute the mean of the values in `x` where `where` is `True`.\n    Args:\n        x: The array to compute the mean of.\n        where: A function that takes a value and returns `True` or `False`. Default is `lambda x: not np.isnan(x)` i.e. a measurement is valid if it is not a `NaN` value.\n    Returns:\n        The mean of the values in `x` where `where` is `True`.\n    \"\"\"\n# Vectorize where fn\nwhere_fn = np.vectorize(pyfunc=where)\nreturn np.mean(x, where=where_fn(x))\n</code></pre> <p>We also encourage using type annotations where possible. For example, the <code>mean_tf</code> function above has type annotations for the input and output types.</p> <p>The following commands can be run for verficiation before opening a PR:</p> <pre><code># Unit tests\npython -m pytest tests\n\n# Linting\nflake8 autonfeat --ignore=E501\n</code></pre> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"getting_started/installation/","title":"Installation","text":""},{"location":"getting_started/installation/#installation","title":"Installation","text":"<p>The package is easy to install.</p>"},{"location":"getting_started/installation/#pip","title":"Pip \ud83d\udce6","text":"<p><code>*(coming soon)*</code></p> <p>It is possible to install using the <code>pip</code> package manager.</p> <p><pre><code>pip install autonfeat\n</code></pre> Installing inside a python virtual environment or a conda environment is recommended.</p>"},{"location":"getting_started/installation/#source","title":"Source \ud83d\udce6","text":"<p>It is also possible to install from <code>source</code>.</p> <pre><code>git clone https://github.com/autonlab/AutonFeat\ncd AutonFeat\npython install -e .\n</code></pre>"},{"location":"getting_started/installation/#jump_in","title":"Jump In \ud83c\udfca\u200d\u2642\ufe0f","text":"<p>If you need help getting started, you can check out any of the following resources we provide:</p> <ul> <li>Introduction</li> <li>Tutorials</li> <li>API Reference</li> <li>Features Extractors</li> <li>Preprocessors</li> </ul> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"getting_started/introduction/","title":"Introduction","text":""},{"location":"getting_started/introduction/#introduction","title":"Introduction","text":"<p><code>AutonFeat</code> is a automatic featurization library for time-series data. It is designed to be used in conjunction with machine learning libraries such as scikit-learn and PyTorch. It is built on design principles similar to that of PyTorch offering a simple and flexible API.</p> <p>More about the package can be found in here. If you are interested in contributing to the project, please see the contributing guide. If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"getting_started/introduction/#why_autonfeat","title":"Why AutonFeat?","text":"<p>What sets this package apart from the many packages already available to researchers and practitioners? We believe that <code>AutonFeat</code> is unique in the following ways:</p> <ul> <li> <p>Automatic: <code>AutonFeat</code> is designed to be used with minimal user input. The user only needs to specify the input data and the featurization method(s). The package will automatically featurize the data and return a set of features that can be used for a downstream task.</p> </li> <li> <p>Simple &amp; Interpretable: <code>AutonFeat</code> is designed to be interpretable. The user can understand the featurization process and the resulting features through good documentation.</p> </li> <li> <p>Flexible &amp; Extensible: <code>AutonFeat</code> is designed to be flexible and extensible. The user can easily extend the package to include custom featurization functions.</p> </li> <li> <p>Fast: <code>AutonFeat</code> is designed to be fast enough to be used in production. Our benchmarks prove the utility of our design choices against existing implementations and packages with truly multi-threaded support. Operations are vectorized where possible and parallelized where necessary. We utilize numba and numpy to speed up the featurization process, escaping Python's Global Interpreter Lock (GIL).</p> </li> </ul>"},{"location":"getting_started/introduction/#jump_in","title":"Jump In","text":"<p>To get started with <code>AutonFeat</code>, we recommend reading the quickstart guide and following the tutorials we've provided here. If you are interested in the API, you can find the documentation here.</p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"tutorials/multi_feature_extraction/","title":"Multi-Feature Extraction","text":""},{"location":"tutorials/multi_feature_extraction/#multi_feature_extraction","title":"Multi Feature Extraction","text":"<p>In this tutorial we will show you how to install and use the <code>AutonFeat</code> package for multi-feature extraction. We apply the package to the problem of time-series forecasting i.e. using past values of a time-series to predict future values. When featurizing time-series signals, it is often useful to extract multiple features from the same signal. For example, we may want to compute a subset of summary statistics (e.g. mean, variance, etc.) on the data. This often makes the job of the model easier in converging to a better performance metric.</p> <p>Feel free to follow along in this Google Colab notebook - </p> <p></p>"},{"location":"tutorials/multi_feature_extraction/#install_packages","title":"Install Packages","text":"<pre><code>%%capture\n!pip install autonfeat\n</code></pre> <pre><code>import autonfeat as aft\nimport numpy as np\nimport pandas as pd\n</code></pre>"},{"location":"tutorials/multi_feature_extraction/#load_dataset","title":"Load Dataset","text":"<p>List available datasets that we can use for this tutorial:</p> <pre><code>print(aft.utils.datasets.list_datasets())\n</code></pre> <pre><code>['airline passengers']\n</code></pre> <p>Load the Airline Passengers dataset:</p> <pre><code>air_passengers_df = aft.utils.datasets.get_dataset(name='airline passengers')\nair_passengers_df['datestamp'] = pd.to_datetime(air_passengers_df['datestamp'])\nair_passengers_df.drop(columns=['uid'], inplace=True)\nair_passengers_df.head()\n</code></pre> datestamp passengers 0 1949-01-31 112.0 1 1949-02-28 118.0 2 1949-03-31 132.0 3 1949-04-30 129.0 4 1949-05-31 121.0 <p>Plot the time-series (it is often useful to visualize the data before we start modeling):</p> <pre><code>import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1, figsize = (10, 5))\nplot_df = air_passengers_df.set_index('datestamp')\nplot_df[['passengers']].plot(ax=ax, linewidth=2)\nax.set_title('Airline Passengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp (t)', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n</code></pre> <p></p>"},{"location":"tutorials/multi_feature_extraction/#preprocess_data","title":"Preprocess Data","text":"<p>We can compute lag features using the preprocessing library from <code>AutonFeat</code>. This is often useful for time-series forecasting problems. We can combine this with feature extraction of summary statistics to create a rich set of features for our model (we will see this in the next section).</p> <pre><code># Define the number of lagged values to include as features\nlags = [1, 2, 3]\npreprocessor = aft.preprocess.LagPreprocessor()\n# Create lagged features\nfor lag in lags:\nair_passengers_df[f'passengers_lag{lag}'] = preprocessor(air_passengers_df['passengers'].values, lag=lag)\n</code></pre>"},{"location":"tutorials/multi_feature_extraction/#feature_extraction","title":"Feature Extraction","text":"<p>Set the parameters of the sliding window to perform feature extraction:</p> <ul> <li><code>window_size</code>: the size of the sliding window</li> <li><code>step_size</code>: the stride of the sliding window</li> <li><code>overflow</code>: what to do with the last window if it is smaller than <code>window_size</code></li> </ul> <p>In this case, we choose to use the <code>stop</code> overflow strategy which means that we will stop the sliding window if the last window is smaller than <code>window_size</code>.</p> <pre><code># Sliding Window\nwindow_size = 12\nstep_size = 1\nsliding_window = aft.SlidingWindow(window_size=window_size, step_size=step_size, overflow='stop')\n</code></pre> <p>Define the features we want to extract from the time-series. We will extract the following features from the data:</p> <ul> <li><code>mean</code>: The mean of the signal (at each window).</li> <li><code>min</code>: The minimum value of the signal (at each window).</li> <li><code>max</code>: The maximum value of the signal (at each window).</li> <li><code>median</code>: The median of the signal (at each window).</li> </ul> <pre><code>transforms = [\naft.MeanTransform(),\naft.MinTransform(),\naft.MaxTransform(),\naft.MedianTransform(),\n]\nfeature_names = []\nfor transform in transforms:\nfeaturizer = sliding_window.use(transform=transform)\nfeatures = featurizer(air_passengers_df['passengers'].values)\n# We add NaNs to the end of the array to make it the same length of the original array\nfeatures = np.append(features, np.repeat(np.nan, len(air_passengers_df) - len(features)))\n# Add the features to the dataframe\nair_passengers_df[f'passengers_{transform.get_name().lower()}'] = features\nfeature_names.append(f'passengers_{transform.get_name().lower()}')\n</code></pre> <p>Here is what our data looks like after preprocessing and feature extraction:</p> <pre><code>air_passengers_df.head()\n</code></pre> datestamp passengers passengers_lag1 passengers_lag2 passengers_lag3 passengers_mean passengers_min passengers_max passengers_median 0 1949-01-31 112.0 NaN NaN NaN 126.666667 104.0 148.0 125.0 1 1949-02-28 118.0 112.0 NaN NaN 126.916667 104.0 148.0 125.0 2 1949-03-31 132.0 118.0 112.0 NaN 127.583333 104.0 148.0 127.5 3 1949-04-30 129.0 132.0 118.0 112.0 128.333333 104.0 148.0 127.5 4 1949-05-31 121.0 129.0 132.0 118.0 128.833333 104.0 148.0 130.5 <p>Lets see what the features looks like:</p> <pre><code># Plot the mean feature with the original data\nfig, ax = plt.subplots(1, 1, figsize = (10, 5))\nplot_df = air_passengers_df.set_index('datestamp')\nplot_cols = ['passengers'] + feature_names\nplot_df[plot_cols].plot(ax=ax, linewidth=2)\nax.set_title('Airline Passengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp (t)', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n</code></pre> <p></p> <p>Feature extraction often results in a decrease in the number of data points. In our case, we chose to handle overflow using the <code>stop</code> strategy as specified in the <code>SlidingWindow</code>. We can see this reduction in the number of data points below:</p> <pre><code># Drop rows with missing values due to the lag\nprint(f'Dataframe contained {air_passengers_df.shape[0]} samples')\nair_passengers_df.dropna(inplace=True)\nprint(f'Dataframe now contains {air_passengers_df.shape[0]} samples')\n</code></pre> <pre><code>Dataframe contained 144 samples\nDataframe now contains 130 samples\n</code></pre> <p>Finally, we split our data into training and test sets.</p> <pre><code>from sklearn.model_selection import train_test_split\n# Split the data into train and test sets\ntrain_df, test_df = train_test_split(air_passengers_df, test_size=0.2, shuffle=False)\n# Define the target variable\ntarget = 'passengers'\n# Define the features to use\nfeatures = ['passengers_lag1', 'passengers_lag2', 'passengers_lag3'] + feature_names\n# Create the feature matrix and target vector\nX_train = train_df[features].values\ny_train = train_df[target].values.reshape(-1, 1)\nX_test = test_df[features].values\ny_test = test_df[target].values.reshape(-1, 1)\nprint('Training set sizes - ', X_train.shape, y_train.shape)\nprint('Test set sizes - ', X_test.shape, y_test.shape)\n</code></pre> <pre><code>Training set sizes -  (104, 7) (104, 1)\nTest set sizes -  (26, 7) (26, 1)\n</code></pre>"},{"location":"tutorials/multi_feature_extraction/#fit_model","title":"Fit Model","text":"<p>We will be using an autoregressive model for time series forecasting. Autoregressive models are a class of models that use past values to predict future values, then use the predicted values to predict even further into the future. One of the simplest autoregressive models is a linear regression model. We will be using the <code>LinearRegression</code> class from <code>sklearn</code> to fit a linear regression model to our data.</p> <pre><code>%%capture\nfrom sklearn.linear_model import LinearRegression\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"tutorials/multi_feature_extraction/#evaluate_model","title":"Evaluate Model","text":"<p>Remember that we adjusted the target values when we performed feature extraction? Well we can now use the remaining data points to evaluate our model. We will be using the mean absolute error (MAE) as our evaluation metric. The MAE is defined as:</p> \\[ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \\] <p>where \\(y_i\\) is the actual value of the time-series at time \\(i\\) and \\(\\hat{y}_i\\) is the predicted value of the time-series at time \\(i\\).</p> <pre><code>from sklearn.metrics import mean_absolute_error\n# Predict on the test set\ny_pred = model.predict(X_test)\n</code></pre> <p>We can evaluate the results both quantitatively and qualitatively. First, lets look at the MAE:</p> <pre><code># Evaluate the model\nmae = mean_absolute_error(y_test, y_pred)\nprint(f'Mean Absolute Error: {mae:.2f}')\n</code></pre> <pre><code>Mean Absolute Error: 28.03\n</code></pre> <p>If we compare this error to that of single-feature extraction (see the single feature extraction tutorial), we are able to get a better performance with multi-feature extraction as the \\(MAE = 32\\) for single-feature extraction and the \\(MAE = 28\\) for multi-feature extraction.</p> <p>Next lets plot the actual values of the time-series against the predicted values:</p> <pre><code>fig, ax = plt.subplots(1, 1, figsize = (10, 5))\nplot_df = test_df.set_index('datestamp')\nplot_df['passengers_pred'] = y_pred\nplot_df[['passengers', 'passengers_pred']].plot(ax=ax, linewidth=2)\nax.set_title('Airline Passengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp (t)', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n</code></pre> <p></p> <p>Here is what it looks like with respect to the original time-series:</p> <pre><code># Plot the training and test sets\nfig, ax = plt.subplots(1, 1, figsize = (10, 5))\ntest_df['passengers_pred'] = y_pred\nplot_df = pd.concat([train_df, test_df]).set_index('datestamp')\nplot_df[['passengers', 'passengers_pred']].plot(ax=ax, linewidth=2)\nax.set_title('Airline Passengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp (t)', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n</code></pre> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"tutorials/single_feature_extraction/","title":"Single-Feature Extraction","text":""},{"location":"tutorials/single_feature_extraction/#single_feature_extraction","title":"Single Feature Extraction","text":"<p>In this tutorial we will show you how to install and use the <code>AutonFeat</code> package for single-feature extraction. We apply the package to the problem of time-series forecasting i.e. using past values of a time-series to predict future values.</p> <p>Feel free to follow along in this Google Colab notebook - </p> <p></p>"},{"location":"tutorials/single_feature_extraction/#install_packages","title":"Install Packages","text":"<pre><code>%%capture\n!pip install autonfeat\n</code></pre> <pre><code>import autonfeat as aft\nimport numpy as np\nimport pandas as pd\n</code></pre>"},{"location":"tutorials/single_feature_extraction/#load_dataset","title":"Load Dataset","text":"<p>List available datasets that we can use for this tutorial:</p> <pre><code>print(aft.utils.datasets.list_datasets())\n</code></pre> <pre><code>['airline passengers']\n</code></pre> <p>Load the Airline Passengers dataset:</p> <pre><code>air_passengers_df = aft.utils.datasets.get_dataset(name='airline passengers')\nair_passengers_df['datestamp'] = pd.to_datetime(air_passengers_df['datestamp'])\nair_passengers_df.drop(columns=['uid'], inplace=True)\nair_passengers_df.head()\n</code></pre> datestamp passengers 0 1949-01-31 112.0 1 1949-02-28 118.0 2 1949-03-31 132.0 3 1949-04-30 129.0 4 1949-05-31 121.0 <p>Plot the time-series (it is often useful to visualize the data before we start modeling):</p> <pre><code>import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1, figsize = (10, 5))\nplot_df = air_passengers_df.set_index('datestamp')\nplot_df[['passengers']].plot(ax=ax, linewidth=2)\nax.set_title('Airline Passengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp (t)', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n</code></pre> <p></p>"},{"location":"tutorials/single_feature_extraction/#preprocess_data","title":"Preprocess Data","text":"<p>We can compute lag features using the preprocessing library from <code>AutonFeat</code>. This is often useful for time-series forecasting problems. We can combine this with feature extraction of summary statistics to create a rich set of features for our model (we will see this in the next section).</p> <pre><code># Define the number of lagged values to include as features\nlags = [1, 2, 3]\npreprocessor = aft.preprocess.LagPreprocessor()\n# Create lagged features\nfor lag in lags:\nair_passengers_df[f'passengers_lag{lag}'] = preprocessor(air_passengers_df['passengers'].values, lag=lag)\n</code></pre>"},{"location":"tutorials/single_feature_extraction/#feature_extraction","title":"Feature Extraction","text":"<p>Set the parameters of the sliding window to perform feature extraction:</p> <ul> <li><code>window_size</code>: the size of the sliding window</li> <li><code>step_size</code>: the stride of the sliding window</li> <li><code>overflow</code>: what to do with the last window if it is smaller than <code>window_size</code></li> </ul> <p>In this case, we choose to use the <code>stop</code> overflow strategy which means that we will stop the sliding window if the last window is smaller than <code>window_size</code>.</p> <pre><code># Sliding Window\nwindow_size = 12\nstep_size = 1\nsliding_window = aft.SlidingWindow(window_size=window_size, step_size=step_size, overflow='stop')\n</code></pre> <p>Define the feature we want to extract from the time-series. Here we will be considering the mean of the time-series values in each window. For a particular window of size \\(w\\), the mean is defined as:</p> \\[ \\text{mean} = \\frac{1}{w} \\sum_{i=1}^{w} x_i \\] <p>where \\(x_i\\) is the value of the time-series at time \\(i\\).</p> <pre><code>feature_extractor = aft.MeanTransform()\nfeaturizer = sliding_window.use(feature_extractor)\nfeatures = featurizer(air_passengers_df['passengers'].values)\n# We add NaNs to the end of the array to make it the same length of the original array\nfeatures = np.append(features, np.repeat(np.nan, len(air_passengers_df) - len(features)))\n# Add the features to the dataframe\nair_passengers_df['passengers_mean'] = features\n</code></pre> <p>Here is what our data looks like after preprocessing and feature extraction:</p> <pre><code>air_passengers_df.head()\n</code></pre> datestamp passengers passengers_lag1 passengers_lag2 passengers_lag3 passengers_mean 0 1949-01-31 112.0 NaN NaN NaN 126.666667 1 1949-02-28 118.0 112.0 NaN NaN 126.916667 2 1949-03-31 132.0 118.0 112.0 NaN 127.583333 3 1949-04-30 129.0 132.0 118.0 112.0 128.333333 4 1949-05-31 121.0 129.0 132.0 118.0 128.833333 <p>Lets see what the mean feature looks like:</p> <pre><code># Plot the mean feature with the original data\nfig, ax = plt.subplots(1, 1, figsize = (10, 5))\nplot_df = air_passengers_df.set_index('datestamp')\nplot_df[['passengers', 'passengers_mean']].plot(ax=ax, linewidth=2)\nax.set_title('Airline Passengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp (t)', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n</code></pre> <p></p> <p>Feature extraction often results in a decrease in the number of data points. In our case, we chose to handle overflow using the <code>stop</code> strategy as specified in the <code>SlidingWindow</code>. We can see this reduction in the number of data points below:</p> <pre><code># Drop rows with missing values due to the lag\nprint(f'Dataframe contained {air_passengers_df.shape[0]} samples')\nair_passengers_df.dropna(inplace=True)\nprint(f'Dataframe now contains {air_passengers_df.shape[0]} samples')\n</code></pre> <pre><code>Dataframe contained 144 samples\nDataframe now contains 130 samples\n</code></pre> <p>Finally, we split our data into training and test sets.</p> <pre><code>from sklearn.model_selection import train_test_split\n# Split the data into train and test sets\ntrain_df, test_df = train_test_split(air_passengers_df, test_size=0.2, shuffle=False)\n# Define the target variable\ntarget = 'passengers'\n# Define the features to use\nfeatures = ['passengers_lag1', 'passengers_lag2', 'passengers_lag3', 'passengers_mean']\n# Create the feature matrix and target vector\nX_train = train_df[features].values\ny_train = train_df[target].values.reshape(-1, 1)\nX_test = test_df[features].values\ny_test = test_df[target].values.reshape(-1, 1)\nprint('Training set sizes - ', X_train.shape, y_train.shape)\nprint('Test set sizes - ', X_test.shape, y_test.shape)\n</code></pre> <pre><code>Training set sizes -  (104, 4) (104, 1)\nTest set sizes -  (26, 4) (26, 1)\n</code></pre>"},{"location":"tutorials/single_feature_extraction/#fit_model","title":"Fit Model","text":"<p>We will be using an autoregressive model for time series forecasting. Autoregressive models are a class of models that use past values to predict future values, then use the predicted values to predict even further into the future. One of the simplest autoregressive models is a linear regression model. We will be using the <code>LinearRegression</code> class from <code>sklearn</code> to fit a linear regression model to our data.</p> <pre><code>%%capture\nfrom sklearn.linear_model import LinearRegression\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"tutorials/single_feature_extraction/#evaluate_model","title":"Evaluate Model","text":"<p>Remember that we adjusted the target values when we performed feature extraction? Well we can now use the remaining data points to evaluate our model. We will be using the mean absolute error (MAE) as our evaluation metric. The MAE is defined as:</p> \\[ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \\] <p>where \\(y_i\\) is the actual value of the time-series at time \\(i\\) and \\(\\hat{y}_i\\) is the predicted value of the time-series at time \\(i\\).</p> <pre><code>from sklearn.metrics import mean_absolute_error\n# Predict on the test set\ny_pred = model.predict(X_test)\n</code></pre> <p>We can evaluate the results both quantitatively and qualitatively. First, lets look at the MAE:</p> <pre><code># Evaluate the model\nmae = mean_absolute_error(y_test, y_pred)\nprint(f'Mean Absolute Error: {mae:.2f}')\n</code></pre> <pre><code>Mean Absolute Error: 32.31\n</code></pre> <p>Next lets plot the actual values of the time-series against the predicted values:</p> <pre><code>fig, ax = plt.subplots(1, 1, figsize = (10, 5))\nplot_df = test_df.set_index('datestamp')\nplot_df['passengers_pred'] = y_pred\nplot_df[['passengers', 'passengers_pred']].plot(ax=ax, linewidth=2)\nax.set_title('Airline Passengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp (t)', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n</code></pre> <p></p> <p>Here is what it looks like with respect to the original time-series:</p> <pre><code># Plot the training and test sets\nfig, ax = plt.subplots(1, 1, figsize = (10, 5))\ntest_df['passengers_pred'] = y_pred\nplot_df = pd.concat([train_df, test_df]).set_index('datestamp')\nplot_df[['passengers', 'passengers_pred']].plot(ax=ax, linewidth=2)\nax.set_title('Airline Passengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp (t)', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n</code></pre> <p></p> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"},{"location":"tutorials/tutorials/","title":"Tutorials","text":"<p>We have prepared several tutorials for you to get started with <code>AutonFeat</code>. We recommend starting with the Getting Started section and then moving on to any one of the following tutorials:</p> <ul> <li>Single-Feature Extraction for Time Series</li> <li>Multi-Feature Extraction for Time Series</li> </ul> <p>If you enjoy using <code>AutonFeat</code>, please consider starring the repository \u2b50\ufe0f.</p>"}]}